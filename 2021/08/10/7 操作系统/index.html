

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/Lsh.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="暂无摘要">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
  <title>操作系统 - laobanjiu</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.7.2/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"laobanjiu9527.github.io","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":" ","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>老斑鸠</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/snoopy3.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="操作系统">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-08-10 08:46" pubdate>
        2021年8月10日 早上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      48.5k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      499
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">操作系统</h1>
            
            <div class="markdown-body">
              <h1 id="1-操作系统概述"><a href="#1-操作系统概述" class="headerlink" title="1. 操作系统概述"></a>1. 操作系统概述</h1><h2 id="1-1-操作系统的概念"><a href="#1-1-操作系统的概念" class="headerlink" title="1.1 操作系统的概念"></a>1.1 操作系统的概念</h2><h3 id="1-1-1-操作系统的定义"><a href="#1-1-1-操作系统的定义" class="headerlink" title="1.1.1 操作系统的定义"></a>1.1.1 操作系统的定义</h3><p>操作系统（OS，Operating System）是计算机系统中最重要的系统软件，它是控制计算机软、硬件资源和方便用户管理的程序集合。</p>
<h3 id="1-1-2-操作系统的特性"><a href="#1-1-2-操作系统的特性" class="headerlink" title="1.1.2 操作系统的特性"></a>1.1.2 操作系统的特性</h3><ol>
<li><p>并发性</p>
<p>并发性是指两个或多个事件在同一时间间隔内发生。并发性和并行性两个概念既相似又有区别：并行性是指两个或多个事件在同一时刻发生。</p>
<p>在多道程序环境下，并发性是指在一段时间内宏观上有多个程序在同时运行，在单处理机系统中，每一时刻仅能有一道程序执行，因此微观上这些程序只能分时交替地执行。</p>
<p>并发特征是操作系统最重要的特征，后续三个特征都以并发特征为前提。</p>
</li>
<li><p>共享性</p>
<p>由于操作系统具有并发性，整个系统的软、硬件资源不再为某个程序所独占，而是由许多程序共同使用，即许多程序共享系统中的各种资源。并发性和共享性相辅相成，是操作系统的两个基本的特征。</p>
</li>
<li><p>虚拟性</p>
<p>虚拟性是指通过某种技术把一个物理实体变为若干个逻辑上的对应物。</p>
<p>用于实现虚拟的技术被称为虚拟技术。操作系统中利用两种方式来实现虚拟技术：</p>
<ul>
<li><p>时分复用技术</p>
<p>在计算机领域中，广泛利用时分复用技术来实现虚拟处理机、虚拟设备等，以提高资源的利用率。</p>
</li>
<li><p>空分复用技术</p>
<p>使用空分复用技术来提高存储空间的利用率，如虚拟磁盘等。</p>
</li>
</ul>
</li>
<li><p>异步性</p>
<p>异步性是指在多道程序环境下，每个程序何时执行、何时暂停未知，即以不可预知的速度向前推进。</p>
<p>只要在操作系统中配置有完善的进程同步机制，且运行环境相同，作业经多次运行都会获得完全相同的结果。</p>
</li>
</ol>
<h3 id="1-1-3-操作系统的作用"><a href="#1-1-3-操作系统的作用" class="headerlink" title="1.1.3 操作系统的作用"></a>1.1.3 操作系统的作用</h3><ol>
<li><p>用户与计算机硬件系统之间的接口</p>
<p>从一般用户的角度看，操作系统是用户与计算机硬件系统之间的接口，用户可通过<strong>命令</strong>、<strong>系统调用</strong>、<strong>图形及窗口</strong>方式使用计算机：</p>
<ol>
<li><p>命令方式</p>
<p>OS提供了一组联机命令接口，以允许用户通过键盘输入有关命令来取得操作系统的服务，并控制用户程序的运行。</p>
</li>
<li><p>系统调用方式</p>
<p>OS提供了一组系统调用，用户可在自己的应用程序中通过相应的系统调用，来实现与操作系统的通信，并取得它的服务。</p>
</li>
<li><p>图形、窗口方式</p>
<p>这是当前使用最为方便、最为广泛的接口，它允许用户通过屏幕上的窗口和图标来实现与操作系统的通信，并取得它的服务。</p>
</li>
</ol>
</li>
<li><p>计算机系统资源的管理者</p>
<p>从资源管理的角度看，<strong>操作系统是计算机系统资源的管理者</strong>。</p>
<p><strong>在一个计算机系统中，资源可分为处理器、存储器、I/O 设备及信息（数据和程序）四类</strong>。</p>
<p>相应地，操作系统也针对这四类资源进行有效管理：</p>
<ol>
<li>处理机管理，分配和控制处理机</li>
<li>存储器管理，负责内存的分配与回收</li>
<li>I/O 设备管理，负责 I/O 设备的分配与操纵</li>
<li>文件管理，负责文件的存取、共享和保护</li>
</ol>
</li>
<li><p>实现对计算机资源的抽象</p>
<p>操作系统还实现了对计算机资源的抽象，隐藏了对硬件操作的细节，使用户能够更方便地使用机器。</p>
</li>
</ol>
<h3 id="1-1-4-操作系统的目标"><a href="#1-1-4-操作系统的目标" class="headerlink" title="1.1.4 操作系统的目标"></a>1.1.4 操作系统的目标</h3><p>在计算机硬件上配置操作系统，主要目标是为了实现方便性、有效性、可扩充性和开放性。</p>
<p>方便性是为了使得计算机系统更容易使用，有效性是为了提高系统资源利用率和吞吐量，方便性和有效性是设计操作系统时最重要的两个目标。</p>
<p>可扩充性使得操作系统能适应计算机硬件、体系结构以及应用发展的要求；开放性指操作系统能遵循世界标准规范，特别是遵循开放系统互连（OSI Open System Interconnect）国际标准，开放性是操作系统能否被广泛应用的重要因素。</p>
<h2 id="1-2-操作系统的发展"><a href="#1-2-操作系统的发展" class="headerlink" title="1.2 操作系统的发展"></a>1.2 操作系统的发展</h2><h3 id="1-2-1-无操作系统的计算机系统"><a href="#1-2-1-无操作系统的计算机系统" class="headerlink" title="1.2.1 无操作系统的计算机系统"></a>1.2.1 无操作系统的计算机系统</h3><ol>
<li><p>人工操作方式</p>
<p>计算机发展早期，还未出现操作系统，计算机的操作由用户采用人工操作方式直接使用计算机硬件系统。这种人工操作方式的缺点是：用户独占全机，CPU 等待人工操作，故严重降低了计算机资源的利用率。此外，高速 CPU 与低速 I/O 设备之间速度不匹配的矛盾也日益突出。</p>
</li>
<li><p>脱机输入/输出方式</p>
<p>为解决上述问题引入了脱机输入/输出技术，此名称的由来源于程序和数据的输入和输出是在脱离主机的情况下进行：脱机输入方式是指在一台外围机的控制下，先将程序和数据从低速的输入设备输入到磁带，当 CPU 需要这些程序和数据时，再从磁带高速地读入内存；脱机输出方式则正好相反。</p>
<p>这种方式下，由外围机而不是 CPU 等待人工操作，并且 CPU 直接通过高速磁带进行输入/输出，因而较好地缓和了 CPU 与 I/O 设备之间速度不匹配的问题。</p>
</li>
</ol>
<h3 id="1-2-2-批处理系统"><a href="#1-2-2-批处理系统" class="headerlink" title="1.2.2 批处理系统"></a>1.2.2 批处理系统</h3><ol>
<li><p>单道批处理系统</p>
<p>单道批处理系统是指系统对作业的处理都是成批地进行，且在内存中始终只保持一道作业。单道批处理系统是最早出现的一种操作系统，其主要特征有自动性、顺序性、单道性。</p>
</li>
<li><p>多道批处理系统</p>
<p>为了进一步提高资源的利用率和系统吞吐量，又引入了多道程序设计技术，由此形成了多道批处理系统：用户所提交的作业都先存放在外存上并排成一个后备队列，然后，由作业调度程序按一定的算法从后备队列中选择若干个作业调入内存，使它们共享 CPU 和系统中的各种资源。</p>
<p>多道批处理系统的主要优缺点如下：</p>
<ol>
<li>资源利用率高</li>
<li>系统吞吐量大</li>
<li>平均周转时间长。作业的周转时间是指从作业进入系统开始，到作业完成为止的这段时间间隔</li>
<li>无交互能力。用户一旦把作业提交给系统后，直至作业完成，用户都不能与自己的作业进行交互，修改和调试程序极为不便</li>
</ol>
</li>
</ol>
<h3 id="1-2-3-分时系统"><a href="#1-2-3-分时系统" class="headerlink" title="1.2.3 分时系统"></a>1.2.3 分时系统</h3><p>分时系统是指在一台主机上连接了多个带有显示器和键盘的终端，同时允许多个用户通过自己的终端，以交互方式使用计算机，共享主机中的资源。</p>
<p>分时系统可以归纳成以下四个特点：</p>
<ol>
<li><p>多路性（同时性）</p>
<p>允许在一台主机上同时连接多台联机终端，系统按分时原则为每个用户服务。宏观上，是多个用户同时工作；而微观上，则是每个用户作业轮流运行一个时间片。</p>
</li>
<li><p>独立性</p>
<p>每个用户各占一个终端，彼此独立操作，互不干扰，用户感觉像是自己一人独占主机。</p>
</li>
<li><p>及时性</p>
<p>用户的请求能在很短的时间内获得响应。</p>
</li>
<li><p>交互性</p>
<p>用户可通过终端与系统进行广泛的人机对话。</p>
</li>
</ol>
<h3 id="1-2-4-实时系统"><a href="#1-2-4-实时系统" class="headerlink" title="1.2.4 实时系统"></a>1.2.4 实时系统</h3><p>实时系统是指系统能及时响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地运行。</p>
<p>实时系统有以下五个特点：</p>
<ol>
<li><p>多路性</p>
<p>实时控制系统的多路性主要表现在系统周期性地对多路现场信息进行采集，以及对多个对象或多个执行机构进行控制。</p>
</li>
<li><p>独立性 </p>
<p>实时控制系统中，对信息的采集和对对象的控制彼此互不干扰。</p>
</li>
<li><p>及时性 </p>
<p>实时控制系统的及时性，以控制对象所要求的开始截止时间或完成截止时间来确定，一般为秒级到毫秒级，甚至更低。</p>
</li>
<li><p>交互性 </p>
<p>实时信息处理系统也具有交互性，但仅限于访问系统中某些特定的专用服务程序。</p>
</li>
<li><p>可靠性 </p>
<p>分时系统虽然也要求系统可靠，但相比之下，实时系统则要求系统具有高度的可靠性，因为任何差错都可能带来巨大的经济损失，甚至是无法预料的灾难性后果。</p>
</li>
</ol>
<h3 id="1-2-5-微机操作系统"><a href="#1-2-5-微机操作系统" class="headerlink" title="1.2.5 微机操作系统"></a>1.2.5 微机操作系统</h3><p><strong>批处理系统</strong>、<strong>分时系统</strong>和<strong>实时系统</strong>是操作系统的三种基本类型。</p>
<p>随着计算机的不断发展和应用需求的不断扩大，操作系统也先后形成了微机操作系统、网络操作系统等。</p>
<p>配置在微型机上的操作系统称为微机操作系统，按运行方式可分为如下几类：</p>
<ol>
<li><p>单用户单任务操作系统</p>
<p>单用户单任务操作系统只允许一个用户上机，且只允许用户程序作为一个任务运行，这是最简单的微机操作系统，最有代表性的单用户单任务微机操作系统是 MS-DOS。</p>
</li>
<li><p>单用户多任务操作系统</p>
<p>单用户多任务操作系统只允许一个用户上机，但允许用户把程序分为若干个任务，使它们并发执行，从而有效地改善了系统的性能。最有代表性的单用户多任务操作系</p>
<p>统是由微软公司推出的 Windows7 等。</p>
</li>
<li><p>多用户多任务操作系统</p>
<p>多用户多任务操作系统允许多个用户通过各自的终端使用同一台机器，而每个用户程序又可进一步分为几个任务，使它们能并发执行，从而可进一步提高资源利用率和系统吞吐量。在大、中和小型机中所配置的大多是多用户多任务操作系统，最有代表性的是 Unix 和 Linux。</p>
</li>
</ol>
<h3 id="1-2-6-网络操作系统"><a href="#1-2-6-网络操作系统" class="headerlink" title="1.2.6 网络操作系统"></a>1.2.6 网络操作系统</h3><p>网络操作系统是使计算机在网络中能方便地传送信息和共享资源，并能为网络用户提供各种所需服务的操作系统。</p>
<p>由于网络计算的出现和发展，现代操作系统的主要特征之一就是具有上网功能，因此，除了在 20 世纪 90 年代初期时，Novell 公司的 Netware 等系统被称为网络操作系统之外，一般不再特指某个操作系统为网络操作系统。</p>
<h2 id="1-3-操作系统的功能"><a href="#1-3-操作系统的功能" class="headerlink" title="1.3 操作系统的功能"></a>1.3 操作系统的功能</h2><p>操作系统具有处理机管理，存储器管理，设备管理和文件管理的功能。此外，还须向用户提供用户接口和面向网络的服务功能。</p>
<h3 id="1-3-1-处理机管理功能"><a href="#1-3-1-处理机管理功能" class="headerlink" title="1.3.1 处理机管理功能"></a>1.3.1 处理机管理功能</h3><p>处理机的管理主要是对进程的管理，在引入了线程的操作系统中，也包含对线程的管理，其主要功能是创建和撤销进程，对各进程的运行进行协调，实现进程之间的信息交换，以及按照一定的算法把处理机分配给进程。</p>
<ol>
<li><p>进程控制</p>
<p>进程控制的主要功能是为作业创建进程，撤销已结束的进程，以及控制进程在运行过程中的状态转换。</p>
</li>
<li><p>进程同步</p>
<p>进程是以异步方式运行的，为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。进程同步的主要任务是为多个进程的运行进行协调，有两种协调方式： 进程互斥和同步方式。</p>
</li>
<li><p>进程通信</p>
<p>进程通信的任务就是用来实现在相互合作的进程之间的信息交换。</p>
</li>
<li><p>调度</p>
<p>在后备队列上等待的每个作业都需经过调度才能执行。调度主要包括作业调度和进程调度。</p>
</li>
</ol>
<h3 id="1-3-2-存储器管理功能"><a href="#1-3-2-存储器管理功能" class="headerlink" title="1.3.2 存储器管理功能"></a>1.3.2 存储器管理功能</h3><p>存储器管理的主要任务是为多道程序的运行提供良好的环境，方便用户使用存储器，提高存储器的利用率以及能从逻辑上扩充内存。为此，存储器管理应具有<strong>内存分配</strong>、<strong>内存保护</strong>、<strong>地址映射</strong>和<strong>内存扩充</strong>等功能。</p>
<h3 id="1-3-3-设备管理功能"><a href="#1-3-3-设备管理功能" class="headerlink" title="1.3.3 设备管理功能"></a>1.3.3 设备管理功能</h3><p>设备管理用于管理计算机系统中所有的外围设备，具有缓冲管理、设备分配、设备处理及虚拟设备等功能。</p>
<h3 id="1-3-4-文件管理功能"><a href="#1-3-4-文件管理功能" class="headerlink" title="1.3.4 文件管理功能"></a>1.3.4 文件管理功能</h3><p>文件管理的主要任务是对用户文件和系统文件进行管理，以方便用户使用，并保证文件的安全性。为此，文件管理应具有<strong>对文件存储空间的管理</strong>、<strong>目录管理</strong>、<strong>文件的读/写管理</strong>，以及<strong>文件的共享与保护</strong>等功能。</p>
<h3 id="1-3-5-操作系统与用户之间的接口"><a href="#1-3-5-操作系统与用户之间的接口" class="headerlink" title="1.3.5 操作系统与用户之间的接口"></a>1.3.5 操作系统与用户之间的接口</h3><p>为了方便用户使用，操作系统又提供了用户与操作系统的接口，该接口通常可分为两大类：</p>
<ol>
<li><p>用户接口</p>
<p>为了便于用户直接或间接地控制自己的作业，操作系统向用户提供了命令接口。用户可通过该接口向作业发出命令以控制作业的运行。该接口可分为联机用户接口和脱机用户接口。</p>
<ol>
<li><p>联机用户接口</p>
<p>终端用户利用该接口可以调用操作系统的功能，取得操作系统的服务。用户可以使用联机控制命令来对自己的作业进行控制。联机用户接口可以实现用户与计算机间的交互。</p>
</li>
<li><p>脱机用户接口</p>
<p>该接口是专为批处理作业的用户提供的，也称批处理用户接口。操作系统提供了一个作业控制语言 JCL（Job Control Language），用户使用 JCL 语言预先写好作业说明书，将它和作业的程序与数据一起提交给计算机，当该作业运行时，OS 将逐条按照用户作业说明书的控制语句，自动控制作业的执行。</p>
<p>脱机用户接口不能实现用户与计算机间的交互。</p>
</li>
</ol>
</li>
<li><p>程序接口</p>
<p>程序接口是操作系统专门为用户程序设置的，由一组系统调用组成，每一个系统调用都是一个能完成特定功能的子程序，是操作系统与应用程序之间的接口，它是用户程序取得操作系统服务的唯一途径。可以说，系统调用提供了用户程序和操作系统之间的接口，应用程序通过系统调用实现其与操作系统的通信，并可取得它的服务。</p>
<p>通常，在操作系统的核心中都设置了一组用于实现各种系统功能的子程序，并将它们提供给应用程序调用。由于这些程序是 OS 系统本身程序模块中的一部分，为了保护操作系统程序不被用户程序破坏，一般都不允许用户程序访问操作系统的程序和 数据，也不允许应用程序采用一般的过程调用方式来直接调用这些过程，而是向应用程序提供了一系列的系统调用命令，让应用程序通过系统调用去调用所需的系统过程。</p>
<p>在计算机系统中，通常运行着两类程序：<strong>系统程序</strong>和<strong>应用程序</strong>，为了保证系统程序不被应用程序有意或无意地破坏，为<strong>计算机设置了两种状态：系统态（也称为管态 或核心态）和用户态（也称为目态）</strong>。操作系统在系统态运行，而应用程序只能在用户态运行。在实际运行过程中，处理机会在系统态和用户态间切换。相应地，<strong>现代多数操作系统将 CPU 的指令集分为特权指令和非特权指令两类</strong>：</p>
<ol>
<li><p>特权指令</p>
<p>特权指令是在系统态时运行的指令，是关系到系统全局的指令。特权指令只允许操作系统使用，不允许应用程序使用，否则会引起系统混乱。</p>
</li>
<li><p>非特权指令</p>
<p>非特权指令是在用户态时运行的指令。一般应用程序所使用的都是非特权指令，它只能完成一般性的操作和任务。</p>
</li>
</ol>
<p>当应用程序中需要操作系统提供服务如请求 I/O 资源或执行 I/O 操作时，应用程序必须使用系统调用命令。操作系统捕获到该命令后，便将 CPU 的状态从用户态转换到系统态，然后执行操作系统中相应的子程序，完成所需的功能。执行完成后，系统又将 CPU 状态从系统态转换到用户态，再继续执行应用程序。</p>
</li>
</ol>
<h2 id="1-4-操作系统的结构"><a href="#1-4-操作系统的结构" class="headerlink" title="1.4 操作系统的结构"></a>1.4 操作系统的结构</h2><h3 id="1-4-1-无结构操作系统"><a href="#1-4-1-无结构操作系统" class="headerlink" title="1.4.1 无结构操作系统"></a>1.4.1 无结构操作系统</h3><p>在早期开发操作系统时，设计者缺乏首尾一致的设计思想。此时的操作系统只是一组过程的集合，每个过程可以任意地调用其它过程，致使操作系统内部复杂而混乱，这种操作系统是无结构的。</p>
<h3 id="1-4-2-模块化结构操作系统"><a href="#1-4-2-模块化结构操作系统" class="headerlink" title="1.4.2 模块化结构操作系统"></a>1.4.2 模块化结构操作系统</h3><p>模块化程序设计技术是基于“分解”和“模块化”原则来控制大型软件的复杂度。 为使操作系统具有较为清晰的结构，将操作系统按其功能划分为若干个具有一定独立性和大小的模块，每个模块具有某方面的管理功能，并规定好各模块间的接口，使各模块之间能通过该接口实现交互。然后，再将各模块细分为若干个具有一定功能的子 模块，同样也要规定好各子模块之间的接口。若子模块较大时，可再进一步将它细分。这种设计方法称为模块-接口法，由此构成的操作系统就是具有模块化结构的操作系统。</p>
<p>模块化结构设计中，各模块的设计齐头并进，无法寻找到一个可靠的决定顺序， 造成各种决定的无序性，因此模块–接口法又被称为无序模块法。</p>
<p><img src="/images/image-20210810102227006.png" srcset="/img/loading.gif" lazyload alt="image-20210810102227006"></p>
<h3 id="1-4-3-分层式结构操作系统"><a href="#1-4-3-分层式结构操作系统" class="headerlink" title="1.4.3 分层式结构操作系统"></a>1.4.3 分层式结构操作系统</h3><p>为了将模块–接口法中“决定顺序”的无序性变为有序性，引入了有序分层法。分层法的设计任务是，在目标系统和裸机系统之间，铺设若干个层次的软件，使目标 系统通过这些层，最终能在裸机系统上运行。在操作系统中，常采用自底向上法来铺 设这些中间层，其基本原则是：每一步设计都是建立在可靠的基础上。为此规定每一层仅能使用其底层所提供的功能和服务，这样可使系统的调试和验证都变得更容易。</p>
<p>分层结构的主要优点有：易保证系统的正确性、易扩充和易维护性。其主要缺点是：系统效率降低。由于层次结构是分层单向依赖的，操作系统每执行一个功能，通常要自上而下地穿越多个层次，增加了系统的通信开销，从而导致系统效率的降低。</p>
<h3 id="1-4-4-微内核操作系统结构"><a href="#1-4-4-微内核操作系统结构" class="headerlink" title="1.4.4 微内核操作系统结构"></a>1.4.4 微内核操作系统结构</h3><p>当前比较流行的、能支持多处理机运行的操作系统，几乎都采用了微内核结构。下面从四个方面对微内核结构的操作系统进行描述。</p>
<ol>
<li><p>足够小的内核</p>
<p>在微内核操作系统中，内核是指精心设计的、能实现现代操作系统最基本的核心功能的部分。微内核并非是一个完整的操作系统，而只是操作系统中最基本的部分，它通常用于：实现与硬件紧密相关的处理；实现一些较基本的功能；负责客户和服务器之间的通信。它们只是为构建通用操作系统提供一个重要基础，这就确保把操作系统内核做得很小。</p>
</li>
<li><p>基于客户/服务器模式</p>
<p>由于客户/服务器模式具有很多的优点，故在单机微内核操作系统中几乎都采用客户/服务器模式，将操作系统中最基本的部分放入内核中，而把操作系统的绝大部分功能都放在微内核外面的一组服务器进程中实现。</p>
</li>
<li><p>应用“机制与策略分离”原理</p>
<p>在现代操作系统的结构设计中，经常利用“机制与策略分离”的原理来构造操作系统结构。机制是指实现某一功能的具体执行机构，策略则是在机制的基础上，借助于某些参数和算法来实现该功能的优化，或达到不同的功能目标。在微内核操作系统中，通常将机制放在操作系统的微内核中，因此才有可能将内核做得很小。</p>
</li>
<li><p>采用面向对象技术</p>
<p>操作系统是一个极其复杂的大型软件系统，不仅可以通过结构设计来分解操作系统的复杂度，还可以基于面向对象技术中的“抽象”和“隐蔽”原则控制系统的复杂性，再进一步利用“对象”、“封装”和“继承”等概念来确保操作系统的正确性、可靠性、易扩展性等，面向对象技术被广泛应用于现代操作系统的设计中。</p>
</li>
</ol>
<p>微内核结构的操作系统具有如下优点：提高了系统的可扩展性，增强了系统的可靠性、可移植性，提供了对分布式系统的支持，融入了面向对象技术。</p>
<p>在微内核操作系统中，采用了非常小的内核，以及客户/服务器模式和消息传递机制，这些虽给微内核操作系统带来了许多优点，但由此也使微内核操作系统的运行效 率有所降低。</p>
<h1 id="2-进程管理"><a href="#2-进程管理" class="headerlink" title="2. 进程管理"></a>2. 进程管理</h1><h2 id="2-1-进程的概念"><a href="#2-1-进程的概念" class="headerlink" title="2.1 进程的概念"></a>2.1 进程的概念</h2><h3 id="2-1-1-基本概念"><a href="#2-1-1-基本概念" class="headerlink" title="2.1.1 基本概念"></a>2.1.1 基本概念</h3><ol>
<li><p>程序</p>
<p>程序是指令的有序集合，是一个在时间上严格按次序前后相继的操作序列，仅当前一操作执行完后，才能执行后继操作，它是一个静态的概念。</p>
<p>程序的执行方式有顺序执行和并发执行两种，这两种方式间有着显著不同的特征。</p>
<ol>
<li><p>程序的顺序执行</p>
<p>程序顺序执行时的特征包括：</p>
<ol>
<li><p>顺序性 </p>
<p>—个程序各个部分的执行，严格地按照某种先后次序执行。</p>
</li>
<li><p>封闭性 </p>
<p>程序在封闭的环境下运行，即程序运行时独占全部系统资源，资源的状态（除初始状态外）只有本程序才能改变它。程序一旦开始执行，其执行结果不受外界因素影响。</p>
</li>
<li><p>可再现性 </p>
<p>只要程序执行时的环境和初始条件相同，当程序重复执行时，都将获得相同的结果。</p>
</li>
</ol>
</li>
<li><p>程序的并发执行</p>
<p>程序的并发执行，虽然提高了系统吞吐量，但也产生了一些与顺序执行时不同的特征：</p>
<ol>
<li><p>间断性 </p>
<p>程序在并发执行时，由于它们共享资源或为完成同一任务而相互合作，致使在并发执行的程序之间形成了相互制约的关系，具有“执行–暂停–执行”的特征。</p>
</li>
<li><p>失去封闭性 </p>
<p>程序在并发执行时，系统中的资源状态将由多个程序来改变，使程序的运行失去了封闭性。</p>
</li>
<li><p>不可再现性 </p>
<p>程序在并发执行时，由于失去了封闭性，其计算结果与并发程序的执行速度有关，程序经过多次执行后，虽然执行时的环境和初始条件相同，但得到的结果却大不相同。</p>
</li>
</ol>
</li>
</ol>
</li>
<li><p>进程</p>
<p>为使程序能并发执行，并且为了对并发执行的程序加以描述和控制，引入了进程的概念。进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</p>
<p>进程的特征包括：</p>
<ol>
<li><p>动态性 </p>
<p>进程的实质是进程实体的一次执行过程，故动态性是进程最基本的特征。动态性还表现在：“它由创建而产生，由调度而执行，由撤销而消亡”。可见，进程实体有 一定的生命期，而程序则只是一组有序指令的集合，其本身并不具有运动的含义，因而是静态的。</p>
</li>
<li><p>并发性</p>
<p>并发性是指多个进程实体同存于内存中，且能在一段时间内同时运行。并发性是进程的重要特征，同时也成为操作系统的重要特征。引入进程的目的也正是为了使其进程实体能和其它进程实体并发执行，而程序是不能并发执行的。</p>
</li>
<li><p>独立性 </p>
<p>独立性是指进程实体是一个能独立运行、独立分配资源和独立接受调度的基本单位。</p>
</li>
<li><p>异步性 </p>
<p>异步性是指进程按各自独立的、不可预知的速度向前推进，或说进程实体按异步方式运行。</p>
</li>
<li><p>结构特征</p>
<p>为使程序能独立运行，应为之配置一进程控制块，即 PCB（Process Control Block）；而由<strong>程序段、相关的数据段和 PCB 三部分便构成了进程实体</strong>。在许多情况下所说的进 程，实际上是指进程实体，创建进程，实质上是创建进程实体中的 PCB；而撤销进程，实质上是撤销进程的 PCB。</p>
<p>PCB 是进程实体的一部分，是操作系统中最重要的记录型数据结构。PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。</p>
<p>在进程的整个生命期中，系统总是通过 PCB 对进程进行控制的，即<strong>系统是根据进程的 PCB 感知该进程的存在，PCB 是进程存在的唯一标志。</strong>因为 PCB 经常被系统访问，故 PCB 应常驻内存。</p>
<p>进程控制块中主要包括四方面的信息：进程标识符、处理机状态、进程调度信息和控制信息。</p>
</li>
</ol>
</li>
<li><p>线程</p>
<ol>
<li><p>概念</p>
<p>在操作系统中引入进程的目的，是为了使多个程序能并发执行，以提高资源利用率和系统吞吐量，再引入线程，则是为了减少程序在并发执行时所付出的时空开销，使操作系统具有更好的并发性。</p>
<p>在多线程操作系统中，将拥有资源的基本单位与调度和分派的基本单位分开处理，<strong>进程只是拥有资源的基本单位，而不再是一个可执行的实体</strong>，<strong>每个线程都是一个可执行的实体，是 CPU 调度和分派的基本单位</strong>。此时，一个进程中含有一个或多个相对独 立的线程，由于线程比进程更小，基本上不拥有系统资源，故对它的调度所付出的开销就会小得多，能更高效地提高系统内多个程序间并发执行的程度。</p>
<p>线程可以利用线程标识符和一组状态参数（包括寄存器、运行状态等现场信息）来描述，并具有下述属性：</p>
<ol>
<li><p>轻型实体 </p>
<p>除了一点在运行中必不可少的资源外，线程基本上不拥有系统的资源。</p>
</li>
<li><p>独立调度和分派的基本单位 </p>
<p>线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。</p>
</li>
<li><p>可并发执行 </p>
<p>同一个进程中的多个线程，以及不同进程中的多个线程均可以并发地执行。</p>
</li>
<li><p>共享进程资源 </p>
<p>同一个进程中的各线程可以共享该进程所拥有的全部资源，如进程的地址空间、已打开的文件等。</p>
</li>
</ol>
</li>
<li><p>线程和进程的比较 </p>
<p>下面从调度、并发、资源和系统开销等方面对线程和进程进行比较：</p>
<ol>
<li><p>调度 </p>
<p>在传统的操作系统中，作为拥有资源的基本单位和独立调度、分派的基本单位都是进程。在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，线程基本上不拥有资源。</p>
</li>
<li><p>并发 </p>
<p>在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间也可并发执行。</p>
</li>
<li><p>资源 </p>
<p>不论是传统的操作系统，还是引入了线程的操作系统，进程都可以拥有资源，是系统中拥有资源的一个基本单位。一般而言，线程自己不拥有系统资源（也有一点必不可少的资源），但它可以访问其隶属进程的资源，即一个进程的代码段、数据段及所拥有的系统资源。</p>
</li>
<li><p>系统开销 </p>
<p>在创建或撤销进程时，系统都要为之创建和回收进程控制块，分配或回收资源，操作系统所付出的开销明显大于线程创建或撤销时的开销。</p>
</li>
</ol>
</li>
</ol>
</li>
</ol>
<h3 id="2-1-2-进程状态"><a href="#2-1-2-进程状态" class="headerlink" title="2.1.2 进程状态"></a>2.1.2 进程状态</h3><ol>
<li><p>三种基本状态</p>
<p>进程具有以下三种基本状态：</p>
<ol>
<li><p>就绪 </p>
<p>进程已获得除了 CPU 以外的所有必要资源，只要再获得 CPU，便可立即执行，此时的状态称为就绪状态。</p>
</li>
<li><p>执行（或运行） </p>
<p>进程已获得 CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态；在多处理机系统中，则有多个进程处于执行状态。</p>
</li>
<li><p>阻塞（或等待） </p>
<p>正在执行的进程由于发生某事件（如请求 I/O）而暂时无法继续执行时，便放弃处理机而处于暂停状态，这种暂停状态称为阻塞状态，有时也称等待状态。</p>
<p><img src="/images/image-20210810110615568.png" srcset="/img/loading.gif" lazyload alt="image-20210810110615568"></p>
</li>
</ol>
</li>
<li><p>挂起状态</p>
<ol>
<li><p>引入挂起状态的原因 </p>
<p>不少系统中进程只有上述三种状态，但在另一些系统中，又增加了挂起状态。引入挂起状态的原因有：</p>
<ol>
<li>终端用户的请求 </li>
</ol>
<p>当终端用户在自己的程序运行期间发现有可疑问题时，希望暂时使自己的程序静止下来，以便用户研究其执行情况或对程序进行修改。这种静止状态称为挂起状态。</p>
<ol start="2">
<li>父进程请求 </li>
</ol>
<p>有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。</p>
<ol start="3">
<li>负荷调节的需要 </li>
</ol>
<p>当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。</p>
<ol start="4">
<li>操作系统的需要 </li>
</ol>
<p>操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。</p>
</li>
<li><p>进程状态的转换 </p>
<p>在引入挂起状态后，又将增加从挂起状态（也称静止状态）到非挂起状态（又称活动状态）的转换；或者相反。可有以下几种情况：</p>
<ol>
<li>活动就绪→静止就绪 </li>
</ol>
<p>当进程处于未被挂起的就绪状态时，称它为活动就绪状态。当该进程挂起后，该进程便转变为静止就绪状态，进程不再被调度执行。</p>
<ol start="2">
<li>静止就绪→活动就绪 </li>
</ol>
<p>处于静止就绪状态的进程被激活后，该进程将转变为活动就绪状态。</p>
<ol start="3">
<li>活动阻塞→静止阻塞 </li>
</ol>
<p>当进程处于未被挂起的阻塞状态时，称它处于活动阻塞状态。当进程挂起后，便转变为静止阻塞状态。处于该状态的进程在其所期待的事件出现后，将从静止阻塞变为静止就绪。</p>
<ol start="4">
<li>静止阻塞→活动阻塞 </li>
</ol>
<p>处于静止阻塞状态的进程被激活后，该进程将转变为活动阻塞状态。</p>
</li>
</ol>
</li>
<li><p>创建状态和终止状态</p>
<p>在目前实际的系统中，还存在着两种比较常见的进程状态，即创建状态和终止状态：</p>
<ol>
<li><p>创建状态 </p>
<p>当一个新进程被创建时，系统已为其分配了 PCB，但进程自身还未进入内存，即创建工作尚未完成，进程还不能被调度运行，其所处的状态就是创建状态。</p>
</li>
<li><p>终止状态 </p>
<p>当一个进程到达了自然结束点，或是出现了无法克服的错误，或是被操作系统所终结，或是被其他有终止权的进程所终结，它将进入终止状态。进入终止态的进程以后不能再执行，但在操作系统中依然保留一个记录，其中保存状态码和一些计时统计数据，供其它进程收集。一旦其它进程完成了对终止状态进程的信息提取之后，操作系统将删除该进程。</p>
</li>
</ol>
</li>
</ol>
<h2 id="2-2-进程控制"><a href="#2-2-进程控制" class="headerlink" title="2.2 进程控制"></a>2.2 进程控制</h2><p>进程控制是进程管理中最基本的功能。它用于创建一个新进程，终止一个已完成的进程，或终止一个因出现某事件而使其无法运行下去的进程，还可负责进程运行中的状态转换。</p>
<p><strong>原语（Primitive）是由若干条指令组成的，用于完成一定功能的一个过程。它与一般过程的区别在于：它们是“原子操作”。原子操作是指一个操作中的所有动作要么全做，要么全不做，即它是一个不可分割的基本单位，因此，在执行过程中不允许被中断。</strong>原子操作在管态下执行，常驻内存。</p>
<h3 id="2-2-1-进程的创建"><a href="#2-2-1-进程的创建" class="headerlink" title="2.2.1 进程的创建"></a>2.2.1 进程的创建</h3><p>在多道程序环境中，只有进程才能在系统中运行。因此，为使程序能运行，就必须为它创建进程。导致一个进程去创建另一个进程的典型事件有以下四类：用户登录；作业调度；提供服务；应用请求。</p>
<h3 id="2-2-2-进程的终止"><a href="#2-2-2-进程的终止" class="headerlink" title="2.2.2 进程的终止"></a>2.2.2 进程的终止</h3><p>引起进程终止的事件主要有：</p>
<ol>
<li>正常结束</li>
<li>异常结束。常见的异常事件有：越界错误、非法指令、运行超时、等待超时、I/O 故障等</li>
<li>外界干预。指进程应外界的请求而终止运行。外界干预有：操作员或操作系统干预、父进程请求、父进程终止</li>
</ol>
<h3 id="2-2-3-进程的阻塞与唤醒"><a href="#2-2-3-进程的阻塞与唤醒" class="headerlink" title="2.2.3 进程的阻塞与唤醒"></a>2.2.3 进程的阻塞与唤醒</h3><p>引起进程阻塞和唤醒的事件主要有：请求系统服务；启动某种操作；新数据尚未到达；无新工作可做。</p>
<h2 id="2-3-进程通信"><a href="#2-3-进程通信" class="headerlink" title="2.3 进程通信"></a>2.3 进程通信</h2><p>进程通信，是指进程之间的信息交换。进程之间的互斥和同步，由于其所交换的信息量少而被归结为低级通信。</p>
<p>随着操作系统的发展，用于进程之间实现通信的机制也在发展，并已由早期的低级进程通信机制发展为能传送大量数据的高级通信工具机制。高级通信机制可归结为三大类：共享存储器通信、消息传递以及管道通信。</p>
<h3 id="2-3-1-共享存储器系统"><a href="#2-3-1-共享存储器系统" class="headerlink" title="2.3.1 共享存储器系统"></a>2.3.1 共享存储器系统</h3><p>在共享存储器系统中，相互通信的进程共享某些数据结构或共享存储区，进程之间能够通过这些空间进行通信。主要分为以下两种类型：</p>
<ol>
<li><p>基于共享数据结构的通信方式 </p>
<p>在这种通信方式中，要求诸进程公用某些数据结构，借以实现诸进程间的信息交换。这种通信方式低效，只适于传递相对少量的数据。</p>
</li>
<li><p>基于共享存储区的通信方式 </p>
<p>为了传输大量数据，在存储器中划出了一块共享存储区，诸进程可通过对共享存储区中数据的读或写来实现通信。</p>
</li>
</ol>
<h3 id="2-3-2-消息传递"><a href="#2-3-2-消息传递" class="headerlink" title="2.3.2 消息传递"></a>2.3.2 消息传递</h3><p>消息传递系统是当前应用最为广泛的一种进程间的通信机制。</p>
<p>在该机制中，进程间的数据交换是以格式化的消息为单位的。程序员直接利用操作系统提供的一组通信命令（原语），不仅能实现大量数据的传递，而且还隐藏了通信的实现细节，使通信过程对用户是透明的，从而大大减化了通信程序编制的复杂性，因而获得了广泛的应用。</p>
<p>在当今最为流行的微内核操作系统中，微内核与服务器之间的通信都采用了消息传递机制。</p>
<p>根据其实现方式的不同，可分成<strong>直接通信方式</strong>和<strong>间接通信方式</strong>两种：</p>
<ol>
<li><p>直接通信方式 </p>
<p>这是指发送进程利用 OS 所提供的发送命令，直接把消息发送给目标进程。此时，要求发送进程和接收进程都以显式方式提供对方的标识符。通常，系统提供两条通信命令（原语）：发送消息 Send 和接收消息 Receive 两条原语，前者向一个给定的目标发送一个消息，后者则从一个给定的源接收一条消息。</p>
</li>
<li><p>间接通信方式 </p>
<p>间接通信方式指进程之间的通信需要通过作为共享数据结构的实体。该实体用来暂存发送进程发送给目标进程的消息；接收进程则从该实体中取出对方发送给自己的消息。通常把这种中间实体称为信箱。消息在信箱中可以安全地保存，只允许核准的目标用户随时读取。信箱可由操作系统创建，也可由用户进程创建，创建者是信箱的拥有者。据此，可把信箱分为以下三类：</p>
<ol>
<li>私用信箱 </li>
</ol>
<p>用户进程可为自己建立一个新信箱，并作为该进程的一部分。信箱的拥有者有权从信箱中读取消息，其他用户则只能将自己构成的消息发送到该信箱中。当拥有该信箱的进程结束时，信箱也随之消失。</p>
<ol start="2">
<li>公用信箱 </li>
</ol>
<p>它由操作系统创建，并提供给系统中的所有核准进程使用。核准进程既可把消息发送到该信箱中，也可从信箱中读取发送给自己的消息。通常，公用信箱在系统运行期间始终存在。</p>
<ol start="3">
<li>共享信箱 </li>
</ol>
<p>它由某进程创建，在创建时或创建后指明它是可共享的，同时须指出共享进程的名字。信箱的拥有者和共享者都有权从信箱中取走发送给自己的消息。</p>
</li>
</ol>
<h3 id="2-3-3-管道通信"><a href="#2-3-3-管道通信" class="headerlink" title="2.3.3 管道通信"></a>2.3.3 管道通信</h3><p><strong>“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又称 pipe 文件</strong>。管道是单向的，写进程视管道文件为输出文件，以字符流的形式把大量数据送入管道；读进程视管道文件为输入文件，从管道中接收数据。这种方式首创于 Unix 系统。</p>
<h2 id="2-4-进程同步"><a href="#2-4-进程同步" class="headerlink" title="2.4 进程同步"></a>2.4 进程同步</h2><p>进程同步的主要任务是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。</p>
<h3 id="2-4-1-临界资源和临界区"><a href="#2-4-1-临界资源和临界区" class="headerlink" title="2.4.1 临界资源和临界区"></a>2.4.1 临界资源和临界区</h3><p><strong>在一段时间内只允许一个进程访问的资源称为临界资源</strong>。计算机系统中的许多硬件资源如打印机、磁带机等，以及某些软件中所用的栈、变量和表格，都属于临界资源，它们要求被互斥地共享。 </p>
<p><strong>每个进程中访问临界资源的那段代码被称为临界区</strong>。</p>
<p>如果此刻该临界资源未被访问，进程便可进入临界区对该资源进行访问，并设置它正被访问的标志；如果此刻该临界资源正被某进程访问，则本进程不能进入临界区。因此，必须在临界区前面增加一段用于进行上述检查的代码，把这段代码称为进入区。相应地，在临界区后面也要加上一段称为退出区的代码，用于将临界区正被访问的标志恢复为未被访问的标志。</p>
<h3 id="2-4-2-同步机制应遵循的规则"><a href="#2-4-2-同步机制应遵循的规则" class="headerlink" title="2.4.2 同步机制应遵循的规则"></a>2.4.2 同步机制应遵循的规则</h3><p>为实现进程互斥地进入自已的临界区，可在系统中设置专门的同步机制来协调各进程间的运行。所有的同步机制都应遵循以下四条准则：</p>
<ol>
<li>空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。</li>
<li>忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。</li>
<li>有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入“死等”状态。</li>
<li>让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”状态。</li>
</ol>
<h3 id="2-4-3-信号量机制"><a href="#2-4-3-信号量机制" class="headerlink" title="2.4.3 信号量机制"></a>2.4.3 信号量机制</h3><p>信号量机制是一种进程同步工具，它用信号量及 P(通过)、V（释放） 操作来实现进程的同步和互斥。<strong>信号量的数值与相应资源的使用情况有关：当数值&gt;0 时，表示当前可用资源数量；当数值&lt;0 时，其绝对值表示等待使用该资源的进程个数。</strong>该值仅能由 P 操作、V操作改变（P、V 操作是低级通信方式）。</p>
<p>P 操作 P(S)包含两步：</p>
<ol>
<li>S=S－1；</li>
<li>若 S&lt;0，表示该类资源已分配完毕，该进程进入等待队列；否则继续执行。</li>
</ol>
<p>V 操作 V(S)包含两步：</p>
<ol>
<li>S=S+1；</li>
<li>若 S&lt;=0，释放等待队列中第一个等待信号量的进程；否则继续执行。</li>
</ol>
<p>信号量的应用示例：</p>
<p><img src="/images/image-20210810114231062.png" srcset="/img/loading.gif" lazyload alt="image-20210810114231062"></p>
<p><img src="/images/image-20210810114307005.png" srcset="/img/loading.gif" lazyload alt="image-20210810114307005"></p>
<h3 id="2-4-4-管程"><a href="#2-4-4-管程" class="headerlink" title="2.4.4 管程"></a>2.4.4 管程</h3><p>信号量机制虽然是一种方便、有效的进程同步机制，但每个要访问临界资源的进程都必须自备同步操作 P 操作和 V 操作，这就使大量的同步操作分散在各个进程中。这不仅给系统的管理带来了麻烦，而且还会因同步操作的使用不当而导致系统死锁。因此产生了一种<strong>新的进程同步工具管程（Monitors）</strong>。</p>
<p>管程概念的思路来源：利用共享数据结构抽象地表示系统中的共享资源，把对该共享数据结构实施的操作定义为一组过程。进程对共享资源的申请、释放和其它操作，都通过这组过程对共享数据结构的操作来实现，这组过程还可以根据资源的情况，或接受或阻塞进程的访问，确保每次仅有一个进程使用共享资源，这样就可以统一管理对共享资源的所有访问，实现进程互斥。</p>
<p>代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块，该模块被称为管程。</p>
<p>管程被请求和释放资源的进程所调用，是一种程序设计语言结构成分，和信号量有同等的表达能力，主要有以下特性：</p>
<ol>
<li>模块化。管程是一个基本程序单位，可以单独编译。</li>
<li>抽象数据类型。管程中不仅有数据，而且有对数据的操作。</li>
<li>信息掩蔽。管程中的数据结构只能被管程中的过程访问，这些过程在管程内部定义，供管程外的进程调用，管程中的数据结构以及过程（函数）的具体实现外部不可见。</li>
</ol>
<p>管程和进程不同，主要体现在以下几个方面：</p>
<ol>
<li>虽然二者都定义了数据结构，但进程定义的是私有数据结构 PCB，管程定义的是公共数据结构，如消息队列等；</li>
<li>二者都存在对各自数据结构上的操作，但进程是由顺序程序执行有关的操作，而管程主要是进行同步操作和初始化操作；</li>
<li>设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使用问题；</li>
<li>进程通过调用管程中的过程对共享数据结构实行操作，该过程就如通常的子程序一样被调用，因而管程为被动工作方式，进程则为主动工作方式；</li>
<li>进程之间能并发执行，而管程则不能与其调用者并发；</li>
<li>进程具有动态性，由“创建”而诞生，由“撤销”而消亡，而<strong>管程则是操作系统中的一个资源管理模块</strong>，供进程调用。</li>
</ol>
<h1 id="3-处理机调度"><a href="#3-处理机调度" class="headerlink" title="3. 处理机调度"></a>3. 处理机调度</h1><h2 id="3-1-分级调度"><a href="#3-1-分级调度" class="headerlink" title="3.1 分级调度"></a>3.1 分级调度</h2><h3 id="3-1-1-处理机调度的层次"><a href="#3-1-1-处理机调度的层次" class="headerlink" title="3.1.1 处理机调度的层次"></a>3.1.1 处理机调度的层次</h3><ol>
<li><p>作业调度</p>
<p>1）作业的概念</p>
<p>作业调度又称高级调度，或宏观调度，根据某种算法，把外存上处于后备队列中的那些作业调入内存。</p>
<p>作业是一个比程序更为广泛的概念，是用户要求计算机所做的关于一次业务处理的全部工作。</p>
<p>一个作业通常包括程序、数据和操作说明书三部分，系统根据作业说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。</p>
<p>在作业运行期间，每个作业都必须经过若干个相对独立，又相互关联的顺序加工步骤才能得到结果，这其中的每一个加工步骤称为一个作业步。<strong>一个典型的作业可分为编译、链接、运行三个作业步。</strong></p>
<p>作业控制块（Job Control Block，JCB）是作业在系统中存在的标志，其中保存了系统对作业进行管理和调度所需的全部信息。在 JCB 中所包含的内容因系统而异，通 常应包含的内容有：作业标识、用户名称、用户帐户、作业类型、调度信息、资源使用情况等。</p>
<p>2）作业状态 </p>
<p>一个作业从提交给计算机系统到执行结束退出系统，一般都要经历提交、收容、执行和完成等四个状态。</p>
<p>一个作业在其处于从输入设备进入外部存储设备的过程称为提交状态。处于提交状态的作业，因其信息尚未全部进入系统，所以不能被调度程序选取。</p>
<p>收容状态也称为后备状态。输入管理系统不断地将作业输入到外存中对应部分（也称输入井，即专门用来存放待处理作业信息的一组外存分区）。若一个作业的信息已全部被输入到输入井，那么，在它还未被调度去执行之前，该作业处于收容状态。</p>
<p>作业调度程序从后备作业中选取若干个作业到内存投入运行。它为被选中作业建立进程并分配必要的资源，这时，这些被选中的作业处于执行状态。从宏观上看，这 些作业正处在执行过程中，但从微观上看，在某一时刻，由于处理机总数少于并发执 行的进程数，因此，不是所有被选中作业都占有处理机，其中的大部分处于等待资源 或就绪状态中。那么，究竟哪个作业的哪个进程能获得处理机而真正的执行，要依靠进程调度来决定。</p>
<p>当作业运行完毕，但它所占用的资源尚未全部被系统回收时，该作业处于完成状态。在这种状态下，系统需做诸如打印结果、回收资源等的善后处理工作。</p>
</li>
<li><p>中级调度 </p>
<p>中级调度又称中程调度，引入中级调度的主要目的是为了提高内存利用率和系统吞吐量。为此，应使那些暂时不能运行的进程调至外存上去等待，把此时的进程状态称为挂起状态。中级调度实际上就是存储器管理中的对换功能。</p>
</li>
<li><p>进程调度 </p>
<p>进程调度又称低级调度，或微观调度，它决定就绪队列中的哪个进程应获得处理机。</p>
<p>进程调度的方式有两种：非抢占方式和抢占方式，其中，抢占方式基于的原则有三个：优先权原则、短进程优先原则、时间片原则。</p>
</li>
</ol>
<h3 id="3-1-2-调度算法的准则"><a href="#3-1-2-调度算法的准则" class="headerlink" title="3.1.2 调度算法的准则"></a>3.1.2 调度算法的准则</h3><ol>
<li><p>面向用户的准则</p>
<p>1）周转时间短</p>
<p><strong>从作业被提交给系统开始，到作业完成为止的这段时间间隔称为作业周转时间</strong>。 假设 *T<sub>i</sub>*为作业 <em>i</em> 的周转时间，则平均周转时间 <em>T</em> 的计算公式为：</p>
<p><img src="/images/image-20210810145041079.png" srcset="/img/loading.gif" lazyload alt="image-20210810145041079"></p>
<p>**作业的周转时间 *T<sub>i</sub>*与系统为它提供服务的时间 <em>Ts<sub>i</sub></em> 之比，称为带权周转时间**，则平均带权周转时间 <em>W</em> 的计算公式为：</p>
<p><img src="/images/image-20210810145205121.png" srcset="/img/loading.gif" lazyload alt="image-20210810145205121"></p>
<ol start="2">
<li>响应时间快 </li>
</ol>
<p>响应时间是从用户通过键盘提交一个请求开始，直至系统首次产生响应为止的时间。</p>
<ol start="3">
<li>截止时间的保证 </li>
</ol>
<p>截止时间是指某任务必须开始执行的最迟时间，或必须完成的最迟时间。对于严格的实时系统，其调度方式和调度算法必须能保证这一点，否则将可能造成难以预料的后果。</p>
<ol start="4">
<li>优先权准则 </li>
</ol>
<p>在批处理、分时和实时系统中选择调度算法时，都可遵循优先权准则，以便让某些紧急的作业能得到及时处理。</p>
</li>
<li><p>面向系统的准则</p>
<ol>
<li>系统吞吐量高 </li>
</ol>
<p><strong>吞吐量是指在单位时间内系统所完成的作业数</strong>，这是用于评价批处理系统性能的另一个重要指标，因而是选择批处理作业调度的重要准则。</p>
<ol start="2">
<li>处理机利用率好 </li>
</ol>
<p>对于大、中型多用户系统，由于 CPU 价格十分昂贵，致使处理机的利用率成为衡量系统性能的十分重要的指标，因此在大、中型系统中，在选择调度方式和算法时，应考虑到这一准则。而对于单用户微机或某些实时系统，此准则就不那么重要。</p>
<ol start="3">
<li>各类资源的平衡利用 </li>
</ol>
<p>在大、中型系统中，不仅要使处理机的利用率高，而且还应能有效地利用其它各类资源，如内存、外存和 I/O 设备等。</p>
</li>
</ol>
<h2 id="3-2-调度算法"><a href="#3-2-调度算法" class="headerlink" title="3.2 调度算法"></a>3.2 调度算法</h2><p>在 OS 中调度的实质是一种资源分配。调度算法是指：根据系统的资源分配策略所规定的资源分配算法。对于不同的系统和系统目标，通常采用不同的调度算法：在批处理系统中，为了照顾为数众多的短作业，应采用短作业优先的调度算法；在分时系统中，为了保证系统具有合理的响应时间，应采用轮转法进行调度。目前存在的多种调度算法中，有的算法适用于作业调度，有的算法适用于进程调度，但也有些调度算法既可用于作业调度，也可用于进程调度。</p>
<h3 id="3-2-1-先来先服务调度算法"><a href="#3-2-1-先来先服务调度算法" class="headerlink" title="3.2.1 先来先服务调度算法"></a>3.2.1 先来先服务调度算法</h3><p>先来先服务（First Come First Served，FCFS）调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。FCFS 算法比较有利于长作业（进程），而不利于短作业（进程）。</p>
<p>假设有 5 个进程 A、B、C、D、E，到达时间分别是 0，1，2，3，4，每个进程所需 CPU 的服务时间是 3，6，4，5，2，利用 FCFS 算法进程的调度顺序是 A、B、C、D、E，调度的平均周转时间和平均带权周转时间见表 </p>
<p><img src="/images/image-20210810145844855.png" srcset="/img/loading.gif" lazyload alt="image-20210810145844855"></p>
<h3 id="3-2-2-短作业-进程优先调度算法"><a href="#3-2-2-短作业-进程优先调度算法" class="headerlink" title="3.2.2 短作业/进程优先调度算法"></a>3.2.2 短作业/进程优先调度算法</h3><p>短作业/进程优先调度算法（Shortest Job/Process First，SJ/PF），是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先（SJF）的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先（SPF）调度算法则是从就绪队列中选出一个估计运行时间 最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。</p>
<p>进程调度的顺序是 A、C、E、D、B。需要注意的是短进程优先调度算法中，每次选择的是已进入系统的、要求服务时间最短的进程，因此在此例中进程 A 首先被调度，当进程 A 运行完成后，在已进入系统的B、C、D 三个进程中，选择要求服务时间最短的 C 进程进行调度，然后当 C 进程运行完成后，E 进程也已经进入系统，此时在 B、D、E 三个未被调度的进程中选择，根据每个进程的要求服务的时间，依次执行 E、D、B。</p>
<p><img src="/images/image-20210810150025089.png" srcset="/img/loading.gif" lazyload alt="image-20210810150025089"></p>
<p>SJ/PF 调度算法也存在不容忽视的缺点：该算法对长作业不利；完全未考虑作业的紧迫程度，因而不能保证紧迫性作业/进程会被及时处理；由于作业/进程的长短只 是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。</p>
<h3 id="3-2-3-高优先权优先调度算法"><a href="#3-2-3-高优先权优先调度算法" class="headerlink" title="3.2.3 高优先权优先调度算法"></a>3.2.3 高优先权优先调度算法</h3><p>作为作业调度算法，此算法常被用于批处理系统中，作为进程调度算法，还可用于实时系统中。优先权调度算法可分为：非抢占式优先权算法、抢占式优先权调度算法。</p>
<p>对于最高优先权优先调度算法，其关键在于：它是使用静态优先权，还是用动态优先权，以及如何确定进程的优先权。</p>
<ol>
<li><p>静态优先权 </p>
<p>静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。确定进程优先权的依据：进程类型、进程对资源的需求和用户需求。</p>
</li>
<li><p>动态优先权 </p>
<p>动态优先权是指在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间的增加而改变的，以便获得更好的调度性能。</p>
<p>动态优先权的变化规律可描述为： </p>
<p>优先权 =（等待时间+要求服务时间）/要求服务时间 </p>
<p>​            = 响应时间/要求服务时间 </p>
<p>​            = 响应比</p>
<p>这种算法即为高响应比优先调度算法（Highest Response-ratio Next，HRN），它既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折中。但每次要进行调度之前，都须先做响应比的计算，这会增加系统开销。</p>
<p>在该例中进程的调度顺序是 A、B、E、C、D。开始时系统首先调度进程 A，当进程 A 执行完后分别计算巳进入系统的 B，C，D 三个进程的响应比：</p>
<p><img src="/images/image-20210810150437329.png" srcset="/img/loading.gif" lazyload alt="image-20210810150437329"></p>
<p>得到 B 进程的响应比最高，因此先被调度，当进程 B 运行完后再次计算进程 C、D、E 当前的响应比，根据结果调度进程 E，当进程 E 运行完后重新计算 C、D 两个进程当前的响应比，然后依次调度 C、D。</p>
<p><img src="/images/image-20210810150542408.png" srcset="/img/loading.gif" lazyload alt="image-20210810150542408"></p>
</li>
</ol>
<h3 id="3-2-4-基于时间片的轮转调度算法"><a href="#3-2-4-基于时间片的轮转调度算法" class="headerlink" title="3.2.4 基于时间片的轮转调度算法"></a>3.2.4 基于时间片的轮转调度算法</h3><ol>
<li><p>时间片轮转法 </p>
<p>其基本思想是为每一个进程分配一个时间段，该时间段被称为时间片，即允许该进程运行的时间。每个进程只能依次循环轮流运行，如果时间片结束时进程还在运行，CPU 将剥夺该进程的使用权转而将 CPU 分配给另一个进程。如果进程在时间片结束之前阻塞或结束，CPU 当即进行切换。为了实现进程的循环执行，将每次被中止运行的进程存入就绪队列的末尾，同时将 CPU 分配给就绪队列中的队首进程。该算法是一种简单而又公平的算法，使用非常广泛。</p>
<p><img src="/images/image-20210810150810972.png" srcset="/img/loading.gif" lazyload alt="image-20210810150810972"></p>
<p>上表给出了当时间片大小 q=1 时调度的过程以及进程的周转时间和带权周转时间。每个进程运行一个时间片就进行轮转。进程 E 需要服务时间为 2，因此经过两 轮循环在时间为 10 处结束运行。第三轮循环时进程 A、B、C、D 进行轮转调度，进程 A 在时间为 11 处结束运行。第四轮循环时进程 B、C、D 进行轮转调度，进程 C 在时间 16 处结束运行。第五轮循环只有 B、D 两个进程参与，进程 D 在时间 19 处结束运行，最后进程 B 在时间 20 处运行完成。</p>
</li>
<li><p>多级反馈队列调度算法</p>
<p>前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目 前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程是：</p>
<ol>
<li><p>应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。</p>
<p><img src="/images/image-20210810151138042.png" srcset="/img/loading.gif" lazyload alt="image-20210810151138042"></p>
</li>
<li><p>当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS 原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业（进程）从第一队列依次降到第 n 队列后，在第 n 队列中便采取按时间片轮转的方式运行。</p>
</li>
<li><p>仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～（i-1）队列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时，又有新进程进入优先权较高的队列（第 1～（i-1）中的任何一个队列），则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第i 队列的末尾，把处理机分配给新到的高优先权进程。</p>
</li>
</ol>
</li>
</ol>
<h2 id="3-3-实时调度"><a href="#3-3-实时调度" class="headerlink" title="3.3 实时调度"></a>3.3 实时调度</h2><p>为保证系统能正常工作，实时调度必须能满足实时任务对截止时间的要求。在含有硬实时任务的实时系统中，广泛采用抢占机制。对于一些小型实时系统，如果能预知任务的开始截止时间，则对实时任务的调度可采用非抢占调度机制。</p>
<h3 id="3-3-1-分类"><a href="#3-3-1-分类" class="headerlink" title="3.3.1 分类"></a>3.3.1 分类</h3><p>实时调度算法的分类有：</p>
<ol>
<li><p>非抢占式调度算法 </p>
<ul>
<li><p>非抢占式轮转调度算法； </p>
</li>
<li><p>非抢占式优先调度算法。</p>
</li>
</ul>
</li>
<li><p>抢占式调度算法</p>
<ul>
<li>基于时钟中断的抢占式优先权调度算法在某实时任务到达后，如果该任务的优先级高于当前任务的优先级，这时并不立即抢占当前任务的处理机，而是等到时钟中断到来时，调度程序才剥夺当前任务的执行，将处理机分配给新到的高优先权任务。此算法可用于大多数的实时系统中。</li>
<li>立即抢占的优先权调度算法在这种调度策略中，要求操作系统具有快速响应外部事件中断的能力。一旦出现外部中断，只要当前任务未处于临界区，便立即剥夺当前任务的执行，把处理机分配给请求中断的紧迫任务。</li>
</ul>
</li>
</ol>
<h3 id="3-3-2-常用算法"><a href="#3-3-2-常用算法" class="headerlink" title="3.3.2 常用算法"></a>3.3.2 常用算法</h3><p>常用的实时调度算法有：</p>
<ol>
<li><p>最早截止时间优先算法（Earliest Deadline First，EDF）</p>
<p>该算法是根据任务的开始截止时间来确定任务的优先级。截止时间愈早，其优先级愈高。该算法要求在系统中保持一个实时任务就绪队列，该队列按各任务截止时间的早晚排序。调度程序在选择任务时，总是选择就绪队列中的第一个任务，为之分配处理机，使之投入运行。</p>
</li>
<li><p>最低松弛度优先算法（Least Laxity First，LLF） </p>
<p>该算法是根据任务紧急（或松弛）的程度，来确定任务的优先级。紧急程度（松弛程度）的计算公式为：</p>
<p>​    松弛度＝任务必须完成时间－其本身的运行时间－当前时间。</p>
<p>任务的紧急程度越高（即松弛度越低），其优先级就越高。该算法主要用于可抢占调度方式中，当一任务的最低松弛度减为 0 时，它必须立即抢占 CPU，以保证按截止时间的要求完成任务。</p>
<p>假设在一实时系统中，有两个周期性实时任务 A 和 B，任务 A要求每 20ms 执行一次，执行时间为 10ms；任务 B 要求每 50ms 执行一次，执行时间为 25ms，则任务 A 和 B 每次必须完成的时间分为为 A1，A2，…和 B1，B2，…。</p>
<p><img src="/images/image-20210810151723944.png" srcset="/img/loading.gif" lazyload alt="image-20210810151723944"></p>
<p><img src="/images/image-20210810151757379.png" srcset="/img/loading.gif" lazyload alt="image-20210810151757379"></p>
<p>当刚开始 t1=0 时，A1 的松弛度为 20－10－0=10ms，而 B1 的松弛度为 50－25－0=25ms，故应先调度 A1 执行；</p>
<p>当 t2=10ms 时，A2 的松弛度为 40－10－10=20ms，B1 的松弛度为 50－25－10=15ms，故此时选择 B1 执行；</p>
<p>当 t3=30ms 时，A2 的松弛度减为 0，此时程序应抢占 B1 的处理机而调度 A2 运行；</p>
<p>当 t4=40ms 时，A3 的松弛度为 60－10－40=10ms，而 B1 的松弛度为 50－5－40=5ms，故此时应重新选择调度 B1 执行；</p>
</li>
</ol>
<h2 id="3-4-死锁"><a href="#3-4-死锁" class="headerlink" title="3.4 死锁"></a>3.4 死锁</h2><h3 id="3-4-1-基本概念"><a href="#3-4-1-基本概念" class="headerlink" title="3.4.1 基本概念"></a>3.4.1 基本概念</h3><p>死锁是指多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。</p>
<p>有两个资源 R1 和 R2 供进程 P1 和 P2 共享，P1 已占用资源 R1，P2 已占用资源 R2，此时若 P2 继续要求 R1,P1 要求 R2，则 P1 和 P2 之间便会形成僵局，它们都在等待对方释放自己所需的资源，但同时又不释放自己已占用的资源，从而进入死锁状态。 </p>
<p><img src="/images/image-20210810152107486.png" srcset="/img/loading.gif" lazyload alt="image-20210810152107486"></p>
<ol>
<li><p>死锁产生的原因</p>
<p>产生死锁的原因可归结为如下两点：</p>
<ol>
<li>**竞争资源 **</li>
</ol>
<p>当系统中供多个进程共享的资源如打印机、公用队列等，其数目不足以满足诸进程的需要时，会引起诸进程对资源的竞争而产生死锁。</p>
<ol start="2">
<li>**进程间推进顺序非法 **</li>
</ol>
<p>进程在运行过程中，请求和释放资源的顺序不当，也同样会导致产生进程死锁。</p>
</li>
<li><p>死锁产生的必要条件 </p>
<p>死锁的发生必须具备下列四个必要条件：</p>
<ol>
<li><p><strong>互斥条件</strong> </p>
<p>指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求该资源，则请求者只能等待，直至占有该资源的进程用毕释放。</p>
</li>
<li><p><strong>请求和保持条件</strong> </p>
<p>指进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。</p>
</li>
<li><p><strong>不剥夺条件</strong> </p>
<p>指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。</p>
</li>
<li><p>**环路等待条件 **</p>
<p>指在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，…， Pn}中的 P0正在等待一个 P1占用的资源；P1正在等待 P2占用的资源，……，Pn正在等待已被 P0占用的资源。</p>
</li>
</ol>
</li>
<li><p>死锁的处理 </p>
<p>为保证系统中各进程的正常运行，应事先采取必要的措施，来预防发生死锁。系统已经出现死锁后，则应及时检测到死锁的发生，并采取适当措施来解除死锁。目前，处理死锁的方法可归结为以下四种：</p>
<ol>
<li><p>预防死锁 </p>
<p>这是一种较简单和直观的事先预防的方法。该方法是通过设置某些限制条件，破坏产生死锁的四个必要条件中的一个或几个条件，来预防发生死锁。</p>
</li>
<li><p>避免死锁 </p>
<p>该方法同样是属于事先预防的策略，但它并不须事先采取各种限制措施去破坏产生死锁的四个必要条件，而是在资源的动态分配过程中，用某种方法去防止系统进入不安全状态，从而避免发生死锁。</p>
</li>
<li><p>检测死锁 </p>
<p>这种方法并不须事先采取任何限制性措施，也不必检查系统是否已经进入不安全区，而是允许系统在运行过程中发生死锁。但可通过系统所设置的检测机制，及时地检测出死锁的发生，并精确地确定与死锁有关的进程和资源；然后，采取适当措施，从系统中将已发生的死锁清除掉。</p>
</li>
<li><p>解除死锁 </p>
<p>这是与检测死锁相配套的一种措施。当检测到系统中已发生死锁时，须将进程从死锁状态中解脱出来。常用的实施方法是撤销或挂起一些进程，以便回收一些资源，再将这些资源分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。</p>
</li>
</ol>
</li>
</ol>
<h3 id="3-4-2-避免死锁"><a href="#3-4-2-避免死锁" class="headerlink" title="3.4.2 避免死锁"></a>3.4.2 避免死锁</h3><p>系统的状态分为安全状态和不安全状态，只要能使系统始终都处于安全状态，便可避免发生死锁。</p>
<ol>
<li><p>安全状态 </p>
<p>安全状态，是指系统能按某种进程顺序（P1，P2，…，Pn）（称〈P1，P2，…，Pn〉序列为安全序列），来为每个进程 Pi分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。如果系统无法找到这样一个安全序列，则称系统处于不安全状态。</p>
<p>虽然并非所有的不安全状态都必然会转为死锁状态，但当系统进入不安全状态后，便有可能进入死锁状态。</p>
</li>
<li><p>银行家算法</p>
<p>最有代表性的避免死锁的算法，是 Dijkstra 的银行家算法。（细节先不深入学习）</p>
</li>
</ol>
<h3 id="死锁的检测和解除"><a href="#死锁的检测和解除" class="headerlink" title="死锁的检测和解除"></a>死锁的检测和解除</h3><ol>
<li><p>死锁的检测 </p>
<p>系统死锁可利用资源分配图来描述。该图是由一组结点 N 和一组边 E 所组成的一个对偶 G =（N，E），用圆圈代表一个进程，用方框代表一类资源。由于一种类型的资源可能有多个，用方框中的一个点代表一类资源中的一个资源。</p>
<p>可以利用把资源分配图加以简化的方法，来检测当系统处于 S 状态时是否为死锁状态。</p>
<p><img src="/images/image-20210810153251748.png" srcset="/img/loading.gif" lazyload alt="image-20210810153251748"></p>
<p>在进行一系列的简化后，若能消去资源分配图中所有的边，使所有的进程结点都成为孤立结点，则称该图是可完全简化的；若不能通过任何过程使该图完全简化，则称该图是不可完全简化的。</p>
<p>对于较复杂的资源分配图，不同的简化顺序，都将得到相同的不可简化图。 </p>
<p>死锁定理：S 为死锁状态的充分条件是当且仅当 S 状态的资源分配图是不可完全简化的。</p>
</li>
<li><p>死锁的解除 </p>
<p>当发现有进程死锁时，便应立即把它们从死锁状态中解脱出来。死锁的常用解除方法有两种：<strong>剥夺资源</strong>和<strong>撤销进程</strong>。</p>
</li>
</ol>
<h1 id="4-存储器管理"><a href="#4-存储器管理" class="headerlink" title="4. 存储器管理"></a>4. 存储器管理</h1><h2 id="4-1-存储器概述"><a href="#4-1-存储器概述" class="headerlink" title="4.1 存储器概述"></a>4.1 存储器概述</h2><p>通用计算机的存储层次至少应具有三级：CPU 寄存器、内存和外存。还可根据具体的功能分工细划为寄存器、高速缓存、内存、磁盘缓存、固定磁盘、可移动存储介质等六层。其中，寄存器、高速缓存、内存和磁盘缓存均属于操作系统存储管理的管辖范畴，断电后信息不再存在。固定磁盘和可移动存储介质属于设备管理的管辖范畴，它们存储的信息将被长期保存。</p>
<h3 id="4-1-1-寄存器"><a href="#4-1-1-寄存器" class="headerlink" title="4.1.1 寄存器"></a>4.1.1 寄存器</h3><p>寄存器访问速度最快，完全能与 CPU 协调工作，但价格昂贵，因此容量不可能很大。寄存器的长度一般以字为单位。由于内存的访问速度远低于 CPU 执行指令的速度，为缓和这一矛盾，在计算机系统中引入了寄存器和高速缓存。</p>
<h3 id="4-1-2-高速缓存"><a href="#4-1-2-高速缓存" class="headerlink" title="4.1.2 高速缓存"></a>4.1.2 高速缓存</h3><p>高速缓存是现代计算机结构中的一个重要部件，其容量比寄存器大，而比内存小，访问速度快于内存。通常进程的程序和数据是存放在内存中，使用时被临时复制到高速缓存中。当 CPU 访问信息时，首先检查它是否在高速缓存中，如果已存在，可直接 从中取出使用，以避免访问内存，否则，再从内存中读出信息。由于高速缓存的速度 越高价格也越贵，故有的计算机系统中设置了两级或多级高速缓存。紧靠内存的一级高速缓存的速度最高，而容量最小，二级高速缓存的容量较大，速度较低。</p>
<h3 id="4-1-3-内存"><a href="#4-1-3-内存" class="headerlink" title="4.1.3 内存"></a>4.1.3 内存</h3><p>内存是计算机系统中一个主要部件，用于保存进程运行时的程序和数据。CPU 只能从内存中取得指令和数据。</p>
<h3 id="4-1-4-磁盘缓存"><a href="#4-1-4-磁盘缓存" class="headerlink" title="4.1.4 磁盘缓存"></a>4.1.4 磁盘缓存</h3><p>磁盘的 I/O 速度远低于对内存的访问速度，因此将频繁使用的一部分磁盘数据和信息，暂时存放在磁盘缓存中，可减少访问磁盘的次数。磁盘缓存本身并不是一种实际存在的存储介质，它是利用内存的存储空间来暂存从磁盘中读出（或写入）的信息。</p>
<h3 id="4-1-5-程序的装入与重定位"><a href="#4-1-5-程序的装入与重定位" class="headerlink" title="4.1.5 程序的装入与重定位"></a>4.1.5 程序的装入与重定位</h3><p>将一个用户源程序变为一个可在内存中执行的程序，通常要经过以下三个步骤：首先是编译，由编译程序将用户源代码编译成若干个目标模块；其次是链接，将这些目标模块及所需的库函数，用链接程序链接在一起，形成一个完整的装入模块；最后是装入，由装入程序将这个装入模块装入内存。将一个装入模块装入内存有三种方式：绝对装入方式、可重定位装入方式和动态运行时装入方式。</p>
<ol>
<li><p>绝对装入方式 </p>
<p>若编译时知道程序将驻留在内存的什么位置，则编译程序将产生绝对地址的目标代码。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完全相同，故不须对程序和数据的地址进行修改。</p>
</li>
<li><p>可重定位装入方式 </p>
<p>绝对装入方式只能将目标模块装入到内存中事先指定的位置，因此只适用于单道程序环境。</p>
<p>在多道程序环境下，所得到的目标模块的起始地址通常从 0 开始，程序中的其它地址也都是相对于起始地址计算的，此时应采用可重定位装入方式，将装入模块装入内存的适当位置，这会使得装入模块中的所有逻辑地址与实际装入内存的物理地址不同，这个地址变换的过程称为<strong>地址重定位</strong>。因为把装入模块装入内存时，地址变换在装入时一次性完成，之后不再改变，故又称为静态重定位。</p>
</li>
<li><p>动态运行时装入方式 </p>
<p>可重定位装入方式并不允许程序运行时在内存中移动位置。而实际情况是，在运行过程中，程序在内存中的位置可能经常要改变，此时应采用动态运行时装入的方式：不在程序运行之前进行重定位，而是把这种地址转换推迟到程序执行期间进行，又称动态重定位。</p>
</li>
</ol>
<h2 id="4-2-连续内存分配"><a href="#4-2-连续内存分配" class="headerlink" title="4.2 连续内存分配"></a>4.2 连续内存分配</h2><p>连续分配方式，是指为一个用户程序分配一个连续的内存空间。它又可进一步分为：<strong>单一连续分配</strong>、<strong>固定分区分配</strong>、<strong>动态分区分配</strong>以及<strong>动态重定位分区分配</strong>四种。</p>
<h3 id="4-2-1-单一连续分配"><a href="#4-2-1-单一连续分配" class="headerlink" title="4.2.1 单一连续分配"></a>4.2.1 单一连续分配</h3><p>单一连续分配是最简单的一种存储管理方式，只能用于单用户、单任务的操作系统中。它将内存分为系统区和用户区两部分，系统区仅提供给 OS 使用，通常是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用，其中仅能存放一道作业。</p>
<h3 id="4-2-2-固定分区分配"><a href="#4-2-2-固定分区分配" class="headerlink" title="4.2.2 固定分区分配"></a>4.2.2 固定分区分配</h3><p>固定分区分配是最早的多道程序的存储管理方式，是指系统先把内存划分成若干个大小固定的分区，一旦划分好，在系统运行期间便不再重新划分。为了满足不同程序的存储需求，各分区的大小可以不等，也可以相等，但在每个分区中只装入一道作业。</p>
<p>采用固定分区分配方法存在以下缺点：</p>
<ol>
<li>由于预先规定了分区的大小，使得大作业无法装入，用户不得不采取其他技术加以补救，增加了用户的负担；</li>
<li>内存利用率不高，作业很少能恰好填满分区；</li>
<li>固定分区无法实现动态扩充内存空间的要求；</li>
<li>由于分区个数在系统初启时确定，因此会限制多道运行的程序个数，特别不适于分时系统交互型用户及内存变化很大的情形。</li>
</ol>
<h3 id="4-2-3-动态分区分配"><a href="#4-2-3-动态分区分配" class="headerlink" title="4.2.3 动态分区分配"></a>4.2.3 动态分区分配</h3><p>动态分区分配算法根据进程的实际需要，动态地分配内存空间。在实现可变分区分配时，涉及到分区分配中所用的数据结构、分区分配算法和分区的分配与回收操作三个问题。</p>
<ol>
<li><p>分区分配中的数据结构 </p>
<p>为实现分区分配，系统中必须配置相应的数据结构，用来描述空闲分区和已分配分区的情况。常用的数据结构有以下两种形式：<strong>空闲分区表</strong>和<strong>空闲分区链</strong>。</p>
</li>
<li><p>分区分配算法 </p>
<p>常用的分配算法主要有以下五种：首次适应算法、循环首次适应算法、最佳适应算法、最坏适应算法、快速适应算法。</p>
<p>1）首次适应算法 </p>
<p>该算法将空闲分区按起始地址递增的次序排列，每次分配均从空闲分区表或空闲分区链首开始顺序查找，直至找到第一个能满足要求的空闲分区为止，并按作业的大小从该分区中分割出一块内存空间分配给请求者，剩余的部分仍留在空闲分区表或链 中。该算法优先使用内存低址部分的空闲分区，从而能在高址部分保留较大的空闲分区，但它会在内存的低端留下很多难以利用的小空闲分区，而每次分配时，对空闲分区的查找都必须经过这些分区，从而会增加查找的开销。</p>
<p>2）循环首次适应算法 </p>
<p>该算法由首次适应算法演变而成，每次分配均从上次分配的位置之后开始查找，并将第一个能满足要求的空闲分区分割并分配出去。其特点是内存中的空闲分区分布得更均匀，从而减少查找空闲分区的开销，但它会使存储器中缺乏大的空闲分区。</p>
<p>3）最佳适应算法 </p>
<p>该算法将空闲分区按大小递增的次序排列，每次分配均从空闲分区表或空闲分区链首开始顺序查找，并将第一个能满足要求的空闲分区分割并分配出去。该算法尽管被称为“最佳”，但情况并非总是如此，因为每次分配后所切割下来的剩余部分总是最小的，它会在内存中留下大量难以利用的小空闲分区。</p>
<p>4）最坏适应算法 </p>
<p>该算法将空闲分区按大小递减的次序排列。当作业申请一个空闲区时，先检查空闲分区链（表）的第一个空闲区是否大于或等于所要求的内存长度，若该空闲区长度小于要求，则分配失败，否则分配相应的存储空间给用户，然后修改和调整空闲分区链（表）。该算法的优点是产生碎片的几率最小，缺点主要是使内存中缺乏大的空闲区。</p>
<p>最坏适应算法与首次适应算法、循环首次适应算法、最佳适应算法一起，称为顺序搜索法。</p>
<p>5）快速适应算法 </p>
<p>将空闲分区根据容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，这样，系统中存在多个空闲分区链表，同时在内存中设立一张管理索引表，该表的每一个表项对应一种空闲分区类型，并记录了该类型空闲分区链表表头的指针。空闲分区的分类是根据进程常用的空间大小进行划分，如 2KB、4KB、8KB 等，对于其它大小的分区，如 7KB 这样的空闲区，既可以放在 8KB 的链表中，也可以放在一个特殊的空闲区链表中。</p>
<p><img src="/images/image-20210810160120192.png" srcset="/img/loading.gif" lazyload alt="image-20210810160120192"></p>
</li>
<li><p>内存回收</p>
<p>当进程运行完毕释放内存时，需要进行内存的回收。系统根据回收区的首址，从空闲区链（表）中找到相应的插入点，此时可能出现以下几种情况：</p>
<ol>
<li>回收区与插入点的前一个空闲分区 F1 相邻接。此时应将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区 F1 的大小。</li>
<li>回收分区与插入点的后一空闲分区 F2 相邻接。此时也可将两分区合并，形成新的空闲分区，但用回收区的首址作为新空闲区的首址，大小为两者之和。</li>
<li>回收区同时与插入点的前、后两个分区邻接。此时将三个分区合并，使用 F1 的表项和 F1 的首址，取消 F2 的表项，大小为三者之和。</li>
<li>回收区既不与 F1 邻接，又不与 F2 邻接。这时应为回收区单独建立一新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。</li>
</ol>
</li>
</ol>
<h3 id="4-2-4-可重定位分区分配（动态重定位分区分配）"><a href="#4-2-4-可重定位分区分配（动态重定位分区分配）" class="headerlink" title="4.2.4 可重定位分区分配（动态重定位分区分配）"></a>4.2.4 可重定位分区分配（动态重定位分区分配）</h3><p>在动态分区分配方式中，经过一段时间的分配和回收后，内存中会产生很多小的空闲分区。此时，可能有用户程序因找不到足够大的空闲分区而难以装入，但所有空闲分区容量的总和却足以满足该程序的要求。</p>
<p>上述这些不能被利用的空闲分区可采用以下办法加以解决：将内存中的所有作业进行移动，从而将原来分散的多个空闲分区移到同一处拼接成一个大的空闲分区，以装入用户的作业。这种技术被称为“拼接”或“紧凑”。</p>
<p>可重定位分区分配方式就是在动态分区分配方式的基础上增加紧凑功能，即在找不到足够大的空闲分区、而空闲分区总和却能满足用户的要求时，对内存空间进行紧凑。由于紧凑时，作业要在内存中移动位置，因此，它需要得到动态重定位技术的支持，这也是它被称为动态重定位分区分配的原因。</p>
<h2 id="4-3-分页和分段存储管理"><a href="#4-3-分页和分段存储管理" class="headerlink" title="4.3 分页和分段存储管理"></a>4.3 分页和分段存储管理</h2><p>连续分配方式会形成许多“碎片”，虽然可通过“紧凑”方法加以解决，但须为之付出很大开销。因此，OS 中又引入了离散分配方式，它将一个作业离散地存放到内存中，从而使系统无须紧凑便能很好地解决碎片问题。</p>
<p>如果离散分配的基本单位是页，则称为分页存储管理方式；如果离散分配的基本单位是段，则称为分段存储管理方式。</p>
<h3 id="4-3-1-基本的分页存储管理"><a href="#4-3-1-基本的分页存储管理" class="headerlink" title="4.3.1 基本的分页存储管理"></a>4.3.1 基本的分页存储管理</h3><p>在分页存储管理方式中，如果不具备页面对换功能，则称为基本的分页存储管理方式，它不具有支持实现虚拟存储器的功能，它要求把每个作业全部装入内存后方能运行。</p>
<ol>
<li><p>页面与页表 </p>
<p><strong>基本的分页存储管理方式中，系统将一个进程的逻辑地址空间分成若干个大小相等的片，称为页面或页。</strong>相应地，<strong>将内存空间分成若干个与页面同样大小的块，称为物理块或页框</strong>。内存的分配以块为单位，并允许将一个进程的若干页分别装入到多个不相邻的物理块中。</p>
<p>为了地址映射的方便，页面的大小通常设置成 2 的幂。如果页面的大小为 2<sup>k</sup>字节，逻辑地址的长度为 n 位，可将线性的逻辑地址分成两部分：右边的 k 位为页内位移量（即页内地址）W，左边的 n-k 位为页号 P。</p>
<p><img src="/images/image-20210810161338838.png" srcset="/img/loading.gif" lazyload alt="image-20210810161338838"></p>
<p>在进程运行时，为了能在内存中找到每个页面对应的物理块，系统为每个进程建立了一张页面映射表，简称<strong>页表</strong>，进程的每个页占页表的一个表项，其中记录了相应页对应的内存块的块号，以及用于分页保护的存取控制信息。</p>
<p>下图给出了分页系统的一个内存分配实例，其中页面大小为 4K，用户作业的大小为 11K。由于进程的最后一页不足一块，因此造成了存放该页的物理块中部分空间的浪费，这部分被浪费的空间被称为“页内碎片”。</p>
<p><img src="/images/image-20210810161535970.png" srcset="/img/loading.gif" lazyload alt="image-20210810161535970"></p>
</li>
<li><p>地址变换机构 </p>
<p>页式存储管理系统中，逻辑地址到物理地址的转换是在进程执行的过程中，由硬件地址变换机构借助于页表自动进行的。</p>
<p>【例题】在一个页式存储管理系统中，页表内容如下所示：</p>
<p><img src="/images/image-20210810161651645.png" srcset="/img/loading.gif" lazyload alt="image-20210810161651645"></p>
<p>若页的大小为 4K，则地址转换机构将逻辑地址 100 转换成的物理地址是多少?</p>
<p>【解析】 </p>
<p>页的大小为 4K，逻辑地址为 100，易知所在页号为 0，页内偏移量为 100，由页表可知页号 0 所对应的块号为 2，则其对应的物理地址为 4K×2+100=8292。</p>
<ol>
<li>基本的地址变换机构 </li>
</ol>
<p>通常将作业的页表存放在内存中，而在系统中只设置一个页表寄存器 PTR（Page-Table Register），当一进程因 CPU 调度而转入执行状态时，其页表的内存始址和长度将从该进程的 PCB 中装入页表寄存器。当进程要访问某个逻辑地址中的指令或数据时，地址变换机构自动地将逻辑地址分为页号和页内地址两部分，并将页号与页表寄存器中的页表长度进行比较，若页号大于或等于页表长度，便产生越界中断，否则便以页号为索引去检索页表，从中得到该页的物理块号，送入物理地址寄存器与页内地址拼接，形成对应的物理地址。</p>
<ol start="2">
<li>具有快表的地址变换机构 </li>
</ol>
<p>由于页表存放在内存中，故 CPU 每存取一个指令或数据时都要两次访问内存：第一次是访问内存中的页表，以形成物理地址；第二次才根据物理地址存取指令或数据，这使得计算机的处理速度降低近 1/2。</p>
<p>为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的特殊高速缓冲寄存器，又称为“联想寄存器”或<strong>“快表”</strong>，用以存放当前访问的那些页表项。</p>
<p>在进行地址转换时，地址变换机构自动将逻辑地址中的页号并行地与快表中的所有页号进行比较，若其中有与此相匹配的页号，便可直接从快表中读出该页对应的物理块号，并送到物理地址寄存器中。如果在快表中未找到对应的页号，则仍需访问内存中的页表来进行地址转换，同时还必须将得到的页表项与页号—起装入到快表中，若快表已满，则还需根据置换算法淘汰某个快表项，以装入新的内容。</p>
</li>
<li><p>多级页表</p>
<p>现代的大多数计算机系统都支持非常大的逻辑地址空间，此时，页表就变得非常大，要为它分配一大段连续的内存空间将变得十分困难。</p>
<p>对于该问题，可利用将页表进行分页，并离散地将各个页表存放到内存块中的办法加以解决，此时，必须为离散分配的页表再建立一张页表，称为外层页表，用来记录存放各页表页的内存块号，从而形成了两级页表。在使用两级页表的分页系统中，每次访问一个数据需访问三次内存，故同样需增设快表来有效地提高访问速度。</p>
<p>如果外层页表仍十分大，则可以将它再进行分页，并离散地存放到内存中，然后再通过一张第二级的外层页表来记录存放各外层页表页的内存块号，这样，便形成了三级页表，并可进一步形成更多级的页表。</p>
</li>
</ol>
<h3 id="4-3-2-基本的分段存储管理"><a href="#4-3-2-基本的分段存储管理" class="headerlink" title="4.3.2 基本的分段存储管理"></a>4.3.2 基本的分段存储管理</h3><p>用户通常喜欢将自己的作业按逻辑关系划分成若干段，然后通过段名和段内地址来访问相应的程序或数据，还希望能以段为单位对程序和数据进行共享和保护，并要求分段能动态增长。分页系统虽然能较好地解决动态分区的碎片问题，却难以满足用户的上述要求，因此又引入了分段式存储管理方式。</p>
<p>在分段存储管理方式中，作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息，如主程序段、子程序段、数据段等。每个段都有自己的名字，都从 0 开始编址，并采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定，故各段长度不等。整个作业的地址空间由于是分成多个段，因而是二维的，即其<strong>逻辑地址由段号和段内地址所组成</strong>。</p>
<p>分段地址中的地址具有下图结构：</p>
<p><img src="/images/image-20210810162558702.png" srcset="/img/loading.gif" lazyload alt="image-20210810162558702"></p>
<p>在该地址结构中，允许一个作业最长有64 K个段，每个段的最大长度为64 KB。</p>
<ol>
<li><p>段表</p>
<p>在分段式存储管理系统中，为每个分段分配一个连续的分区，而进程中的各个段可以离散地放入内存不同的分区。系统中为每个进程建立一张段映射表，简称“段表”。 每个段在表中占有一个表项，其中记录了该段在内存中的起始地址和段的长度。段表可以存放在一组寄存器中，但更常多的是放在内存中。</p>
<p>在配置了段表后，执行中的进程可通过查找段表找到每个段所对应的内存区。故段表是用于实现从逻辑段到物理内存区的映射。</p>
</li>
<li><p>地址变换机构 </p>
<p>为了实现从进程的逻辑地址到物理地址的变换功能，在系统中设置了一个段表寄存器，用于存放正在执行进程的段表始址和长度。在进行地址转换时，地址变换机构将逻辑地址中的段号与段表寄存器中的段表长度进行比较，若段号不小于段表长度， 便产生越界中断；否则便以段号为索引去检索段表，从中得到该段的基址和长度；接着检查段内地址是否超过段长，若超过，则发出越界中断信号；若未超过，则将该段的基址与段内地址相加，从而得到对应的物理地址。</p>
<p>【例题】对于下表所示的段表，请将逻辑地址（0，137），（1，4000），（2， 3600），（5，230）转换为物理地址。</p>
<p><img src="/images/image-20210810162925631.png" srcset="/img/loading.gif" lazyload alt="image-20210810162925631"></p>
<p>【解析】 </p>
<ul>
<li>段号 0 小于段表长 5，故段号合法；由段表的第 0 项可获得段的内存始址为50K，段长为 10K；由于段内地址 137 小于段长 10K，故段内地址也是合法的，因此可得出对应的物理地址为 50K+137=51337。</li>
<li>段号 1 小于段表长，故段号合法；由段表的第 1 项可获得段的内存始址为60K，段长为 3K；由于段内地址 4000 超过段长 3K，因此产生越界中断。</li>
<li>段号 2 小于段表长，故段号合法；由段表的第 2 项可获得段的内存始址为70K，段长为 5K；段内地址 3600 小于段长 5K，也是合法的，因此可得出对应的物理地址为70K+3600=75280。</li>
<li>段号 5 等于段表长，故段号不合法，产生越界中断。</li>
</ul>
</li>
<li><p>分页和分段的主要区别</p>
<p>分页和分段系统都采用离散分配方式，且都要通过地址映射机构来实现地址变换，这是它们的相同之处，其不同主要表现在以下三个方面：</p>
<ol>
<li><p>页是信息的物理单位，分页是为提高内存的利用率；段则是信息的逻辑单位，分段的目的是为了能更好地满足用户的需要。</p>
</li>
<li><p>页的大小固定且由系统决定，在系统中只能有一种大小的页面；而段的长度却不固定，取决于用户所编写的程序，通常由编译程序在编译时，根据信息的性质来划分。</p>
</li>
<li><p>分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；而分段的作业地址空间则是二维的，程序员在标识一个 地址时，既需给出段名，又需给出段内地址。</p>
</li>
</ol>
</li>
<li><p>段页式存储管理方式 </p>
<p>为了既能像分页系统那样有效地利用内存，又能像分段系统那样满足用户多方面的需要，操作系统中又引入了段页式存储管理方式。</p>
<p>段页式系统的基本原理，是先将用户程序分成若干个段，再把每个段分成若干个页。<strong>在段页式系统中，其地址结构由段号、段内页号及页内地址三部分所组成</strong>。</p>
<p>在段页式系统中，为获得一条指令或数据须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成物理地址；第三次访问是取指令或数据。</p>
</li>
</ol>
<h2 id="4-4-虚拟存储管理"><a href="#4-4-虚拟存储管理" class="headerlink" title="4.4 虚拟存储管理"></a>4.4 虚拟存储管理</h2><h3 id="4-4-1-局部性原理"><a href="#4-4-1-局部性原理" class="headerlink" title="4.4.1 局部性原理"></a>4.4.1 局部性原理</h3><p>程序局部性原理是指程序在执行时将呈现出局部性规律，即在一较短时间内，程序的执行仅局限于某个部分；相应地，它所访问的存储空间也局限于某个区域。局限性还表现在下述两方面：</p>
<ol>
<li><p>时间局限性 </p>
<p>如果程序中的某条指令一旦执行，则不久以后该指令可能再次执行；如果某数据被访问过，则不久以后该数据可能再次被访问。产生时间局限性的典型原因是由于在程序中存在着大量的循环操作。</p>
</li>
<li><p>空间局限性 </p>
<p>一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，其典型情况便是程序的顺序执行。</p>
</li>
</ol>
<p>基于局部性原理产生了虚拟存储器。</p>
<h3 id="4-4-2-虚拟存储器的实现"><a href="#4-4-2-虚拟存储器的实现" class="headerlink" title="4.4.2 虚拟存储器的实现"></a>4.4.2 虚拟存储器的实现</h3><p><strong>虚拟存储器是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统</strong>。其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。</p>
<p>虚拟存储器的实现，建立在离散分配的存储管理方式的基础上。目前，所有的虚拟存储器都是采用下述方式之一实现的:</p>
<ol>
<li><p>请求分页系统 </p>
<p>在分页系统的基础上，增加了请求调页功能和页面置换功能，便形成页式虚拟存储系统。它允许只装入少数页面的程序及数据，便启动运行。之后再通过调页功能及页面置换功能，陆续地把即将要运行的页面调入内存，同时把暂不运行的页面换出到外存上。</p>
</li>
<li><p>请求分段系统 </p>
<p>在分段系统的基础上，增加了请求调段及分段置换功能后，便形成段式虚拟存储系统。它允许只装入少数而非所有段的用户程序和数据，即可启动运行。之后再通过调段功能和段的置换功能将暂不运行的段调出，同时调入即将运行的段。</p>
</li>
</ol>
<h3 id="4-4-3-虚拟存储器的特征"><a href="#4-4-3-虚拟存储器的特征" class="headerlink" title="4.4.3 虚拟存储器的特征"></a>4.4.3 虚拟存储器的特征</h3><p>虚拟存储器具有<strong>多次性</strong>、<strong>对换性</strong>和<strong>虚拟性</strong>三大主要特征。</p>
<ol>
<li><p>多次性 </p>
<p>多次性是指虚拟存储器将一个作业分成多次调入内存。多次性是虚拟存储器最重要的特征，任何其它的存储管理方式都不具有这一特征。</p>
</li>
<li><p>对换性 </p>
<p>在作业运行期间，虚拟存储器允许将内存中暂时不能运行的进程或暂时不用的程序或数据，调出到外存上，以便腾出足够的内存空间，再把具备运行条件的进程或进程所需要的程序和数据调入内存。</p>
<p>如果对换是以整个进程为单位的，便称之为“整体对换”或“进程对换”。这种对换被广泛地应用于分时系统中，其目的是用来解决内存紧张问题，并可进一步提高内存的利用率。而相应的，如果对换是以“页”或“段”为单位进行的，则分别称之为“页面对换”或“分段对换”，又统称为“部分对换”。它们是实现虚拟存储器的基础。</p>
</li>
<li><p>虚拟性</p>
<p>虚拟性是指能够从逻辑上扩充内存容量，使用户所看到的内存容量远大于实际内存容量。虚拟性是实现虚拟存储器的最重要的目标。</p>
<p>虚拟性是以多次性和对换性为基础的，仅当系统允许将作业分多次调入内存，并能将内存中暂时不运行的程序和数据换至盘上时，才有可能实现虚拟存储器；而多次性和对换性又必须建立在离散分配的基础上。</p>
</li>
</ol>
<h3 id="4-4-4-请求分页存储管理方式"><a href="#4-4-4-请求分页存储管理方式" class="headerlink" title="4.4.4 请求分页存储管理方式"></a>4.4.4 请求分页存储管理方式</h3><p>请求分页系统是建立在基本分页存储管理基础上的，增加了请求调页功能和页面置换功能。请求分页便成为目前最常用的一种实现虚拟存储器的方式。</p>
<p>为了确定所缺的页面调入内存的时机，可采取预调页策略或请求调页策略：</p>
<ol>
<li><p>预调页策略 </p>
<p>如果进程的许多页是存放在外存的一个连续区域中，则一次调入若干个相邻的页，会比一次调入一页更高效些。但如果调入的一批页面中的大多数都未被访问，则又是低效的。可采用一种以预测为基础的预调页策略，将那些预计在不久之后便会被访问的页面预先调入内存。这种策略主要用于进程的首次调入时，由程序员指出应该先调入哪些页。</p>
</li>
<li><p>请求调页策略 </p>
<p>当进程在运行中需要访问某部分程序和数据时，若发现其所在的页面不在内存，便立即提出请求，由 OS 将其所需页面调入内存。由请求调页策略所确定调入的页，是一定会被访问的，再加之请求调页策略比较易于实现，故在目前的虚拟存储器中大多采用此策略。</p>
</li>
</ol>
<h2 id="4-5-页面置换算法"><a href="#4-5-页面置换算法" class="headerlink" title="4.5 页面置换算法"></a>4.5 页面置换算法</h2><p>置换算法的好坏直接影响系统的性能。若采用的置换算法不合适，可能出现这样的现象：刚被换出的页，很快又被访问，为把它调入而换出另一页，之后又访问刚被换出的页……如此频繁地更换页面，以致系统的大部分时间花费在页面的调度和传输上。此时，系统看起来很忙，但实际效率却很低。这种现象称为<strong>“抖动”</strong>。</p>
<p>好的页面置换算法能够适当降低页面更换频率（减少缺页率），尽量避免系统“抖动”。为评价一个算法的优劣，可将该算法应用于一个特定的存储访问序列上，并且计算缺页数量，存储访问序列也叫页面走向。</p>
<h3 id="4-5-1-最佳（OPT）置换算法"><a href="#4-5-1-最佳（OPT）置换算法" class="headerlink" title="4.5.1 最佳（OPT）置换算法"></a>4.5.1 最佳（OPT）置换算法</h3><p>最佳置换算法（Optimal，OPT）是选择不再访问的页面或者是在未来最长时间内不再被访问的页面予以淘汰。最佳页面置换算法是在理论上提出的一种算法，具有最好的性能，但实现是困难的，因为它需要人们预先知道一个进程在整个运行过程中页面走向的全部情况。不过，这个算法可用来衡量其他算法的优劣。</p>
<p>为了讨论页面置换算法，将采用如下页面号引用串：1、2、3、4、1、2、5、1、2、3、4、5，系统为某进程分配了三个物理块，初始状态三个物理块均为空闲。</p>
<p><img src="/images/image-20210810170144177.png" srcset="/img/loading.gif" lazyload alt="image-20210810170144177"></p>
<p>上表列出了物理块数为 3 时的页面置换情况，√表示产生缺页中断，缺页次数为 7，缺页率为 7/12 ≈ 58%。由于初始状态内存的 3 个物理块均为空，因此访问前三个页面 1、2、3 时都会产生缺页中断。当进程第一次对页面 4 进行访问时，首先发出缺页中断，选择 1、2、3 三个页面中未来—段时间内不会访问的页面 3 进行置换，页面 4 换入内存然后进行访问。根据页面走向依次处理，得到最终的置换结果。</p>
<h3 id="4-5-2-先进先出（FIFO）页面置换算法"><a href="#4-5-2-先进先出（FIFO）页面置换算法" class="headerlink" title="4.5.2 先进先出（FIFO）页面置换算法"></a>4.5.2 先进先出（FIFO）页面置换算法</h3><p>FIFO 算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰，该算法的出发点是最早调入内存中的页面，其不再被使用的可能性会比较高。其实现简单、直观，对按线性顺序访问的程序比较合适，面对其他情况则效率不高，因为经常被访问的页面，往往在内存中因停留得最久而被淘汰。</p>
<p><img src="/images/image-20210810170547668.png" srcset="/img/loading.gif" lazyload alt="image-20210810170547668"></p>
<p>上表列出了物理块数为 3 时的页面置换情况，缺页次数为 9， 缺页率为 9/12=75%。</p>
<p><img src="/images/image-20210810170719724.png" srcset="/img/loading.gif" lazyload alt="image-20210810170719724"></p>
<p>一般而言，对于任一作业或进程，如果给它分配的内存页面数越接近于它所要求 的页面数，则发生缺页的次数会越少。在极限情况下，这个推论是成立的，如果给一个进程分配了它所要求的全部页面，则不会发生缺页现象。但是，使用 FIFO 算法时， 在给进程或作业分配满足它所要求的页面数时，有时会出现分配的页面数增多，缺页次数反而增加的奇怪现象，这种现象称为 Belady 现象。</p>
<p>上表给出了物理块数为 4 时的页面置换情况，缺页中断次数为 10。可见系统分配给该进程的物理块数从 3 块变成 4 块，缺页中断次数从 9 次变成 l0 次，缺页次数反而增加。不过，这种现象并不常见。</p>
<h3 id="4-5-3-最近最久未使用（LRU）置换算法"><a href="#4-5-3-最近最久未使用（LRU）置换算法" class="headerlink" title="4.5.3 最近最久未使用（LRU）置换算法"></a>4.5.3 最近最久未使用（LRU）置换算法</h3><p>LRU 算法是根据页面调入内存后的使用情况进行决策的。由于无法预测各页面将来的使用情况，只能以“最近的过去”作为“最近的将来”的近似，选择在最近一段时间里最久没有使用过的页面予以置换。因此，LRU 算法是与每个页面最后使用的时间有关的，当必须置换一个页面时，LRU 算法选择过去一段时间内最久未使用的页面。</p>
<p>对于前面的样例，下表列出了物理块数为 3 时的页面置换情况，缺页次数为10，缺页率为10/12≈83%。</p>
<p><img src="/images/image-20210810170952806.png" srcset="/img/loading.gif" lazyload alt="image-20210810170952806"></p>
<p>LRU 置换算法是一种比较好的算法，但需要硬件的支持：移位寄存器或栈。 </p>
<p>关于确定最后使用时间的问题，对于移位寄存器而言，当进程访问某物理块时，要将相应寄存器的位置成“1”。此时，定时信号将每隔一定时间将寄存器右移一位。如果把 n 位寄存器的数看做是一个整数，那么，具有最小数值的寄存器所对应的页面，就是最近最久未使用的页面。</p>
<p>对于栈而言，每当访问一个页面时，便将它的页面号从栈中移出，压入栈顶。因此栈顶始终是最新被访问页面的编号，而栈底则是最近最久未使用页面的页面号。</p>
<h3 id="4-5-4-Clock-置换算法"><a href="#4-5-4-Clock-置换算法" class="headerlink" title="4.5.4 Clock 置换算法"></a>4.5.4 Clock 置换算法</h3><p>LRU 算法是较好的一种算法，但它要求有较多的硬件支持，故在实际应用中大多采用 LRU 的近似算法。Clock 算法就是用得较多的一种 LRU 近似算法。</p>
<ol>
<li><p>简单的 Clock 置换算法 </p>
<p>Clock 置换算法采用循环队列机制构造页面队列，形成类似于钟表面的环形表，队列指针相当于钟表面上的表针，指向可能要淘汰的页面。它在存储分块表的每一表项中增加一个访问位，操作系统定期地将它们置为 0。当某一页被访问时，由硬件将该位置为 1。过一段时间后，通过检查这些位可以确定哪些页使用过，哪些页自上次置 0 后还未使用过，可把该位是 0 的页淘汰出去，因为在最近一段时间里它未被访问过。由于该算法是循环地检查各页面的使用情况，故称为 Clock 算法。但因该算法只有一位访问位，只能用它表示该页是否已经使用过，而置换时是将未使用过的页面换出去，故又把该算法称为最近未用算法（Not Recently Used，NRU）。</p>
</li>
<li><p>改进型 Clock 置换算法</p>
<p>考虑到如果某一调入内存的页没有被修改过，则不必将它拷回到磁盘。于是在改进的 Clock 算法中增加了一个因素，即置换代价，这样，选择页面换出时，既要考虑未访问过的页面，又要考虑未被修改过的页面，把同时满足这两个条件的页面作为首选淘汰的页面。由访问位 A 和修改位 M 可以组合成下面四种类型的页面：</p>
<ol>
<li>（A=0，M=0）：该页最近既未被访问也未被修改，是最佳淘汰页；</li>
<li>（A=0，M=1）：该页最近未被访问但已被修改，并不是很好的淘汰页；</li>
<li>（A=1，M=0）：该页最近已被访问但未被修改，该页有可能再被访问；</li>
<li>（A=1，M=1）：表示该页最近已被访问且被修改，该页可能再被访问。</li>
</ol>
<p>其执行过程可分成以下三步：</p>
<ol>
<li><p>从开始位置扫描循环队列，寻找 A=0 且 M=0 的第一类页面，找到立即置换。在第一次扫描期间不改变访问位 A。</p>
</li>
<li><p>如果第一步失败，即查找一周后未遇到第一类页面，则开始第二轮扫描，寻找 A=0 且 M=1 的第二类页面，找到后立即置换。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0。</p>
</li>
<li><p>如果第二步也失败，则返回指针开始位置，然后重复第一步，必要时再重复第二步，此时必能找到被淘汰的页。</p>
</li>
</ol>
</li>
</ol>
<h3 id="4-5-5-其它置换算法"><a href="#4-5-5-其它置换算法" class="headerlink" title="4.5.5 其它置换算法"></a>4.5.5 其它置换算法</h3><ol>
<li><p>最少使用（LFU，Least Frequently Used）置换算法</p>
<p>在采用最少使用置换算法时，应为在内存中的每个页面设置一个移位寄存器，用来记录该页面被访问的频率。该置换算法选择在最近时期使用最少的页面作为淘汰页。 由于存储器具有较高的访问速度，通常不能直接利用计数器来记录某页被访问的次数，而是采用移位寄存器方式。</p>
</li>
<li><p>页面缓冲算法（PBA，Page Buffering Algorithm）</p>
<p>页面缓冲算法可改善分页系统的性能，采用一种较简单的置换策略。它采用可变分配和局部置换方式，置换算法采用的是 FIFO。该算法规定将一个被淘汰的页放入两个链表中的一个，即如果页面未被修改，就将它直接放入空闲链表中；否则，便放入已修改页面的链表中。须注意的是，这时页面在内存中并不做物理上的移动，而只是将页表中的表项移到上述两个链表之一中。当被修改的页面数目达到一定值时，再将它们一起写回到磁盘上，从而显著减少了磁盘 I/O 的操作次数。</p>
</li>
</ol>
<h1 id="5-设备管理"><a href="#5-设备管理" class="headerlink" title="5. 设备管理"></a>5. 设备管理</h1><h2 id="5-1-I-O-硬件"><a href="#5-1-I-O-硬件" class="headerlink" title="5.1 I/O 硬件"></a>5.1 I/O 硬件</h2><p>设备管理是操作系统的主要功能之一，其基本任务是完成用户提出的 I/O 请求，提高 I/O 速率以及提高 I/O 设备的利用率。I/O 设备不仅种类繁多，而且特性和操作方式往往相差甚大，这就使得设备管理成为操作系统中最庞杂和琐碎的部分。操作系 统中普遍使用 I/O 中断、通道、缓冲器管理等多种技术，较好地克服了由于外部设备和主机速度不匹配所引起的问题，使主机和外设并行工作，提高了使用效率。</p>
<h3 id="5-1-1-I-O-设备的类型"><a href="#5-1-1-I-O-设备的类型" class="headerlink" title="5.1.1 I/O 设备的类型"></a>5.1.1 I/O 设备的类型</h3><p>I/O 设备的类型繁多，可从不同角度对它们进行分类：</p>
<ol>
<li><p>按设备的使用特性分类 </p>
<p>按设备的使用特性，可将设备分为两类：一类是存储设备，也称外存、辅存，是计算机系统用以存储信息的主要设备；另一类是输入/输出设备，又具体可分为输入设备、输出设备和交互式设备。</p>
</li>
<li><p>按传输速率分类 </p>
<p>按传输速度的高低，可将 I/O 设备分为三类：一是低速设备，如键盘、鼠标等；二是中速设备，如打印机等；三是高速设备，如磁带、磁盘、光盘等。</p>
</li>
<li><p>按信息交换的单位分类 </p>
<p>按信息交换的单位，可将 I/O 设备分成两类：第一类是块设备，这类设备用于存储信息，由于信息的存取是以数据块为单位的，故称其为块设备，属于有结构设备，如磁盘等；第二类是字符设备，用于数据的输入和输出，其基本单位是字符，故称字符设备，属于无结构类型，如交互式终端、打印机等。</p>
</li>
<li><p>按设备的共享属性分类 </p>
<p>这种分类方式可将 I/O 设备分为如下三类：</p>
<ol>
<li>独占设备 </li>
</ol>
<p>独占设备是指在一段时间内只允许一个进程访问的设备，即临界资源。对多个并发进程而言，应互斥地访问这类设备。</p>
<ol start="2">
<li>共享设备 </li>
</ol>
<p>共享设备是指在一段时间内允许多个进程同时访问的设备，如磁盘等。该类设备每一时刻仍然只允许一个进程访问。共享设备不仅可获得良好的设备利用率，而且是实现文件系统和数据库系统的物质基础。</p>
<ol start="3">
<li>虚拟设备 </li>
</ol>
<p>虚拟设备是指通过虚拟技术将一台独占设备变换为若干台逻辑设备，供若干个进程同时使用。</p>
</li>
</ol>
<h3 id="5-1-2-设备控制器"><a href="#5-1-2-设备控制器" class="headerlink" title="5.1.2 设备控制器"></a>5.1.2 设备控制器</h3><ol>
<li><p>概述 </p>
<p>设备控制器是 CPU 与 I/O 设备之间的接口，它接收从 CPU 发来的 I/O 命令，并控制 I/O 设备工作，以使处理机从繁杂的设备控制事务中解脱出来。</p>
<p>设备控制器是一个可编址的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；若控制器可连接多个设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。</p>
<p>设备控制器分成两类：一类是用于控制字符设备，另一类用于控制块设备。在微型机和小型机中的控制器，常做成印刷电路卡形式，因而也常称为接口卡，可将它插入计算机。</p>
<p>设备控制器的基本功能包括：接收和识别命令、数据交换、标识和报告设备的状态、地址识别、数据缓冲和差错控制。</p>
</li>
<li><p>组成 </p>
<p>由于设备控制器位于 CPU 与设备之间，既要与 CPU 通信，又要与设备通信，还应具有按照 CPU 所发来的命令去控制设备工作的功能，因此，大多数控制器都是由以下三部分组成：</p>
<ol>
<li>设备控制器与处理机的接口 </li>
</ol>
<p>该接口用于实现 CPU 与设备控制器之间的通信，共有三类信号线: 数据线、地址线和控制线。数据线通常与两类寄存器相连接，第一类是数据寄存器，用于存放从设备送来的数据或从 CPU 送来的数据；第二类是控制/状态寄存器，用于存放从 CPU 送来的控制信息或设备的状态信息。</p>
<ol start="2">
<li>设备控制器与设备的接口 </li>
</ol>
<p>在一个设备控制器上，可以连接一个或多个设备。相应地，在控制器中便有一个或多个设备接口，一个接口连接一台设备。在每个接口中都存在数据、控制和状态三种类型的信号。控制器中的 I/O 逻辑根据处理机发来的地址信号去选择一个设备接口。</p>
<ol start="3">
<li>I/O 逻辑 </li>
</ol>
<p>在设备控制器中的 I/O 逻辑用于实现对设备的控制，它通过一组控制线与处理机交互，处理机利用该逻辑向控制器发送 I/O 命令，I/O 逻辑对收到的命令进行译码。每当 CPU 要启动一个设备时，一方面将启动命令发送给控制器；另一方面又同时通过地址线把地址发送给控制器，由控制器的 I/O 逻辑对收到的地址进行译码，再根据所译出的命令对所选设备进行控制。</p>
</li>
</ol>
<h2 id="5-2-I-O-软件"><a href="#5-2-I-O-软件" class="headerlink" title="5.2 I/O 软件"></a>5.2 I/O 软件</h2><p>I/O 软件的总体设计目标是高效率和通用性，为使 I/O 软件能具有清晰的结构，更好的可移植性和易适应性，目前在 I/O 软件中已普遍采用了层次式结构，低层软件用于实现与硬件相关的操作，并可屏蔽硬件的具体细节，高层软件则主要向用户提供一个简洁、友好和规范的接口。各层次及其功能如下：</p>
<ol>
<li><p>用户层软件 </p>
<p>用户层软件实现与用户交互的接口，用户层软件必须通过一组系统调用来取得操作系统服务。在现代的高级语言中，用户程序通过调用对应的库函数使用系统调用。</p>
</li>
<li><p>设备独立性软件 </p>
<p>设备独立性软件负责实现与设备驱动器的统一接口、设备命名、设备的保护以及设备的分配与释放等，同时为设备管理和数据传送提供必要的存储空间。</p>
<p>这里的设备独立性是指应用程序独立于具体使用的物理设备。为了实现设备独立性，引入了逻辑设备和物理设备两个概念。在应用程序中，使用逻辑设备名称来请求使用某类设备；而系统在实际执行时，必须使用物理设备名称。因此，系统须具有将逻辑设备名称转换为物理设备名称的功能。这可通过设置一张逻辑设备表(LUT，Logical Unit Table)实现。</p>
</li>
<li><p>设备驱动程序 </p>
<p>设备驱动程序是 I/O 进程与设备控制器之间的通信程序，与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动 I/O 设备工作的驱动程序。</p>
</li>
<li><p>中断处理程序 </p>
<p>中断处理程序用于保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完后恢复被中断进程的现场，再返回到被中断进程。中断处理层的主要工作有：进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态等。</p>
</li>
</ol>
<h2 id="5-3-I-O-控制方式"><a href="#5-3-I-O-控制方式" class="headerlink" title="5.3 I/O 控制方式"></a>5.3 I/O 控制方式</h2><p>I/O 控制方式随着计算机技术的进步也在不断地发展。早期的计算机系统中采用程序 I/O 方式；当引入中断机制后，I/O 方式发展为中断驱动方式；此后，随着 DMA控制器的出现，I/O 方式从以字节为单位的传输扩大到以数据块为单位进行传输，从而大大地改善了块设备的 I/O 性能；而通道的引入，又使对 I/O 操作的组织和数据的传送都能独立地进行而无需 CPU 干预。</p>
<h3 id="5-3-1-程序-I-O-方式"><a href="#5-3-1-程序-I-O-方式" class="headerlink" title="5.3.1 程序 I/O 方式"></a>5.3.1 程序 I/O 方式</h3><p>早期的计算机系统中，处理机对 I/O 设备的控制采取程序 I/O 方式，或称为忙–等待方式，在该方式中，由于 CPU 的高速性和 I/O 设备的低速性，致使 CPU 的绝大部分时间都处于等待 I/O 设备完成数据 I/O 的循环测试中，造成对 CPU 的极大浪费。CPU 之所以要不断地测试 I/O 设备的状态，是因为在 CPU 中无中断机构，使 I/O 设备无法向 CPU 报告它已完成了一个字符的输入操作。</p>
<h3 id="5-3-2-中断驱动-I-O-控制方式"><a href="#5-3-2-中断驱动-I-O-控制方式" class="headerlink" title="5.3.2 中断驱动 I/O 控制方式"></a>5.3.2 中断驱动 I/O 控制方式</h3><p>现代计算机系统都广泛采用中断驱动方式，即当某进程要启动某个 I/O 设备工作时，便由 CPU 向相应的设备控制器发出一条 I/O 命令，然后立即返回继续执行原来的任务。设备控制器于是按照该命令的要求去控制指定 I/O 设备。此时，CPU 与 I/O设备并行操作。</p>
<p>在 I/O 设备输入每个数据的过程中，无需 CPU 干预，可使 CPU 与 I/O 设备并行工作。仅当输完一个数据时，才需 CPU 花费极短的时间去做些中断处理。可见，这样可使 CPU 和 I/O 设备都处于忙碌状态，从而提高了整个系统的资源利用率及吞吐量。</p>
<h3 id="5-3-3-直接存储器访问（DMA）I-O-控制方式"><a href="#5-3-3-直接存储器访问（DMA）I-O-控制方式" class="headerlink" title="5.3.3 直接存储器访问（DMA）I/O 控制方式"></a>5.3.3 直接存储器访问（DMA）I/O 控制方式</h3><p>中断驱动 I/O 方式以字或字节为单位进行 I/O，当完成后，控制器便向 CPU 请求一次中断。为了进一步减少 CPU 对 I/O 的干预，引入了直接存储器访问（DMA，Direct  Memory Access）方式：数据块在 I/O 设备和内存间直接进行传送，每次传送至少一个数据块，在控制器的控制下完成，仅在传送一个或多个数据块的开始和结束时，才需CPU 干预。</p>
<p>可见，DMA 方式进一步提高了 CPU 与 I/O 设备的并行操作程度。</p>
<h3 id="5-3-4-I-O-通道控制方式"><a href="#5-3-4-I-O-通道控制方式" class="headerlink" title="5.3.4 I/O 通道控制方式"></a>5.3.4 I/O 通道控制方式</h3><p>I/O 通道方式是DMA方式的发展，增设通道的主要目的是为了使一些原来由CPU处理的 I/O 任务转由通道来承担，从而把 CPU 从繁杂的 I/O 任务中解脱出来，有更多的时间去进行数据处理。它可进一步减少 CPU 的干预，即把对一个数据块的读/写为单位的干预减少为对一组数据块的读/写及有关的控制和管理为单位的干预。同时，又可实现 CPU、通道和 I/O 设备三者的并行操作，从而更有效地提高整个系统的资源利用率。</p>
<p>I/O 通道是一种特殊的处理机，它具有执行 I/O 指令的能力，并通过执行通道程序来控制 I/O 操作。但它又与一般的处理机不同：一是其指令类型单一，其所能执行的命令主要局限于与 I/O 操作有关的指令；二是通道没有自己的内存，通道所执行的通道程序是放在主机的内存中的，即通道与 CPU 共享内存。</p>
<p>通道可分成以下三种类型：字节多路通道、数组选择通道、数组多路通道。</p>
<ol>
<li><p>字节多路通道</p>
<p>这是一种按字节交叉方式工作的通道。它通常都含有许多非分配型子通道，每一个子通道连接一台 I/O 设备，并控制该设备的 I/O 操作。这些子通道按时间片轮转方 式共享主通道。当所有子通道轮转一周后，又返回来由第一个子通道去使用字节多路主通道。这样，只要字节多路通道扫描每个子通道的速率足够快，而连接到子通道上的设备的速率不是太高时，便不致丢失信息，但不适于连接高速设备。</p>
</li>
<li><p>数组选择通道 </p>
<p>这种通道可以连接多台高速设备，但只含有一个分配型子通道，在一段时间内只能执行一道通道程序，控制一台设备进行数据传送。当某台设备占用了该通道后，便一直由它独占，即使是它无数据传送，通道被闲置，也不允许其它设备使用该通道，直至该设备传送完毕释放该通道。可见这种通道虽有很高的传输速率，但利用率很低，每次只允许一个设备传输数据。</p>
</li>
<li><p>数组多路通道 </p>
<p>数组多路通道是将数组选择通道传输速率高和字节多路通道能使各子通道分时并行操作的优点相结合而形成的一种新通道。它含有多个非分配型子通道，因而既具有 很高的数据传输速率，又能获得令人满意的通道利用率。该通道能被广泛地用于连接多台高、中速的外围设备，其数据传送是按数组方式进行的。</p>
</li>
</ol>
<h2 id="5-4-中断技术"><a href="#5-4-中断技术" class="headerlink" title="5.4 中断技术"></a>5.4 中断技术</h2><p>在计算机系统中，除了输入/输出中断之外，还存在许多其他的突发事件，例如电源掉电、程序出错等，这些也会发出中断信号通知 CPU 做相应的处理。引入中断技术的初衷是提高多道程序运行环境中 CPU 的利用率，而且主要是针对外部设备，后来逐 步发展成为操作系统各项操作的基础，如键盘或鼠标信息的输入、进程的管理和调度、 系统功能的调用、设备驱动、文件访问等，无不依赖于中断机制。可以说，现代操作系统是靠中断驱动的软件。</p>
<h3 id="5-4-1-中断的基本概念"><a href="#5-4-1-中断的基本概念" class="headerlink" title="5.4.1 中断的基本概念"></a>5.4.1 中断的基本概念</h3><p>中断是指计算机在执行期间，系统内发生任何非寻常的或非预期的急需处理事件，使得 CPU 暂时中断当前正在执行的程序而转去执行相应的事件处理程序，待处理完毕后又返回原来被中断处，继续执行或调度新的进程执行的过程。</p>
<p>引起中断发生的事件称为中断源。中断源向 CPU 发出的请求中断处理信号称为中断请求，而 CPU 收到中断请求后转到相应的事件处理程序称为中断响应。</p>
<p>还有一个常用的概念是中断屏蔽。中断屏蔽是指在中断请求产生之后，系统用软件方式有选择地封锁部分中断而允许其余部分的中断仍能得到响应。中断屏蔽是通过每一类中断源设置一个中断屏蔽触发器来屏蔽它们的中断请求而实现的。</p>
<p>不过，有些中断请求是不能屏蔽甚至不能禁止的，即这些中断具有最高优先级。不管 CPU 是否处于关中断，只要这些中断请求一旦提出，CPU 必须立即响应。如电源掉电事件所引起的中断就是不可禁止和屏蔽的中断。</p>
<h3 id="5-4-2-中断的分类与优先级"><a href="#5-4-2-中断的分类与优先级" class="headerlink" title="5.4.2 中断的分类与优先级"></a>5.4.2 中断的分类与优先级</h3><p>根据中断源产生的条件，可把中断分为外中断和内中断。</p>
<p>外中断是指来自处理机和内存外部的中断，包括 I/O 设备发出的 I/O 中断、外部信号中断、各种定时器引起的时钟中断以及调试程序中设置的断点等引起的调试中断等。外中断在狭义上一般称为中断。</p>
<p>内中断主要指在处理机和内存内部产生的中断。内中断一般称为陷阱（trap）。它包括程序运算引起的各种错误，如地址非法、校验错误、页面失效、存取访问控制错误、算术操作溢出、数据格式非法、除数为零、非法指令、用户程序执行特权指令、分时系统中的时间片中断以及从用户态到核心态的切换等都是陷阱的例子。</p>
<p>为了按中断源的轻重缓急处理响应中断，操作系统对不同的中断赋予不同的优先级。为了禁止中断或屏蔽中断，CPU 的处理机状态字 PSW 中也设置有相应的优先级。如果中断源的优先级高于 PSW 的优先级，则 CPU 响应该中断源的中断请求，反之，CPU 屏蔽该中断源的中断请求。各中断源的优先级在系统设计时给定，在系统运行时是固定的。</p>
<p>中断和陷阱的主要区别如下：</p>
<ol>
<li>陷阱通常由处理机正在执行的现行指令引起，而中断则是由与现行指令无关的中断源引起的；</li>
<li>陷阱处理程序提供的服务为当前进程所用，而中断处理程序提供的服务则不是为了当前进程的。</li>
<li>CPU 在执行完一条指令之后，下一条指令开始之前响应中断，而在一条指令执行中也可以响应陷阱。例如执行指令非法时，尽管被执行的非法指令不能执行结束，但 CPU 仍可对其进行处理。</li>
</ol>
<h3 id="5-4-3-软中断"><a href="#5-4-3-软中断" class="headerlink" title="5.4.3 软中断"></a>5.4.3 软中断</h3><p>软中断的概念主要来源于 Unix 系统，软中断是对应于硬中断而言的。上述中断和陷阱都可以看作是硬中断，通过硬件产生相应的中断请求，称为硬中断。而软中断则是通信进程之间用来模拟硬中断而实现的一种信号通信方式。中断源发出软中断信号后，CPU 或接收进程在适当的时机自动进行中断处理，或者完成软中断信号所对应的 功能。这里“适当的时机”指的是接收进程必须得到处理机之后，才能接收软中断信号进程。如果该接收进程是占据处理机的，那么，该接收进程在接收到软中断信号后将立即转去执行该软中断信号所对应的功能。</p>
<h2 id="5-5-缓冲技术"><a href="#5-5-缓冲技术" class="headerlink" title="5.5 缓冲技术"></a>5.5 缓冲技术</h2><p>在设备管理中，引入缓冲区的主要原因可归结为以下几点：</p>
<ol>
<li>缓和 CPU 与 I/O 设备间速度不匹配的矛盾；</li>
<li>减少中断 CPU 的次数，放宽对中断响应时间的限制；</li>
<li>提高 CPU 和 I/O 设备之间的并行性</li>
</ol>
<h3 id="5-5-1-单缓冲"><a href="#5-5-1-单缓冲" class="headerlink" title="5.5.1 单缓冲"></a>5.5.1 单缓冲</h3><p>单缓冲是操作系统提供的一种简单的缓冲技术。每当一个用户进程发出一个 I/O请求时，操作系统在内存的系统区中开设一个缓冲区。</p>
<p>对于块设备输入，单缓冲机制首先从磁盘把一块数据传送到缓冲区，接着操作系统把缓冲区数据送到用户区。由于这时缓冲区已空，操作系统可预读紧接的下一块数据。对于块设备输出，单缓冲机制的工作方式类似，先把数据从用户区拷贝到系统缓冲区，用户进程可以继续请求输出，直到缓冲区填满后，才启动 I/O 将数据写到磁盘上。</p>
<p>假定从磁盘把一块数据输入到缓冲区的时间为 T1，操作系统将该缓冲区中的数据传送到用户区的时间为 T2，而 CPU 对这一块数据处理的时间为 T3。由于 T1 和 T3是可以并行的，当 T1&gt;T3时，系统对每一块数据的处理时间为 T1+T2，反之则为 T3+T2，故可把系统对每一块数据的处理时间表示为 Max(T1，T3)+T2。</p>
<h3 id="5-5-2-双缓冲"><a href="#5-5-2-双缓冲" class="headerlink" title="5.5.2 双缓冲"></a>5.5.2 双缓冲</h3><p>为了加快 I/O 速度，实现 I/O 的并行工作和提高设备利用率，需要引入双缓冲机制。在输入数据时，先将数据送入第一缓冲区，填满后操作系统从第一缓冲区把数据送到用户进程区，用户进程便可对数据进行加工计算；与此同时填充第二缓冲区。当第一缓冲区空出后，输入设备再次向第一缓冲区输入数据。此时，操作系统又可以把 第二缓冲区的数据传送到用户进程区，用户进程开始加工第二缓冲区的数据。两个缓冲区交替使用，使 CPU 和 I/O 设备、I/O 设备和用户进程的并行性进一步提高，仅当两个缓冲区都为空，进程还要提取数据时，它才被迫等待。<strong>双缓冲机制可以同时实现 双向的数据传输，一个缓冲区用作发送缓冲区，另一个缓冲区作为接收缓冲区。</strong></p>
<h3 id="5-5-3-循环缓冲"><a href="#5-5-3-循环缓冲" class="headerlink" title="5.5.3 循环缓冲"></a>5.5.3 循环缓冲</h3><p>当输入与输出的速度相差很大时，双缓冲的效果不够理想，为此又引入了多缓冲机制，可将多个缓冲组织成循环缓冲的形式。在循环缓冲中包括多个缓冲区，其每个缓冲区的大小相同。</p>
<p>对于用作输入的循环缓冲，通常是提供给输入进程或计算进程使用。其中输入进程不断向空缓冲区输入数据，计算进程则从中提取数据进行计算。作为输入的多缓冲区可分为三类：用于装输入数据的空缓冲区 R、已装满数据的缓冲区 G 以及计算进程正在使用的现行工作缓冲区</p>
<p><img src="/images/image-20210810191523647.png" srcset="/img/loading.gif" lazyload alt="image-20210810191523647"></p>
<p>作为输入的缓冲区可设置三个指针：用于指示计算进程下一个可用缓冲区 G 的指针 Nextg、指示输入进程下次可用的空缓冲区 R 的指针 Nexti，以及用于指示计算进程正在使用的缓冲区 C 的指针 Current。</p>
<p>当计算进程要使用缓冲区中的数据时，将指针 Nextg 所指示的缓冲区提供给进程使用，相应地，须把它改为现行工作缓冲区，并令 Current 指针指向该缓冲区的第一 个单元，同时将 Nextg 移向下一个 G 缓冲区。类似地，当输入进程要使用空缓冲区来装入数据时，将指针 Nexti 所指示的缓冲区提供给输入进程使用，同时将 Nexti 指针移向下一个 R 缓冲区。</p>
<p>当计算进程把 C 缓冲区中的数据提取完毕时，将缓冲区 C 释放。此时，把该缓冲区由现行工作缓冲区 C 改为空缓冲区 R。类似地，当输入进程把缓冲区装满时，将该缓冲区释放，并改为 G 缓冲区。</p>
<h3 id="5-5-4-缓冲池"><a href="#5-5-4-缓冲池" class="headerlink" title="5.5.4 缓冲池"></a>5.5.4 缓冲池</h3><p>为了提高缓冲区的利用率，目前广泛使用缓冲池，在池中设置了多个可供若干个进程共享的缓冲区，且既能用于输入，也能用于输出。</p>
<p>缓冲池至少应含有以下三种类型的缓冲区：</p>
<ol>
<li>空缓冲区；</li>
<li>装满输入数据的缓冲区；</li>
<li>装满输出数据的缓冲区。</li>
</ol>
<p>为了管理上的方便，可将相同类型的缓冲区链成一个队列，于是可形成以下三个队列：</p>
<ol>
<li>空缓冲队列。这是由空缓冲区所链成的队列。</li>
<li>输入队列。这是由装满输入数据的缓冲区所链成的队列。</li>
<li>输出队列。这是由装满输出数据的缓冲区所链成的队列。</li>
</ol>
<p>缓冲区可以工作在收容输入、提取输入、收容输出和提取输出四种工作方式下，按使用情况设置有四种工作缓冲区：收容输入工作缓冲区、提取输入工作缓冲区、收容输出工作缓冲区和提取输出工作缓冲区。</p>
<p><img src="/images/image-20210810191838574.png" srcset="/img/loading.gif" lazyload alt="image-20210810191838574"></p>
<h2 id="5-6-设备分配"><a href="#5-6-设备分配" class="headerlink" title="5.6 设备分配"></a>5.6 设备分配</h2><p>在多道程序环境下，系统中的设备供所有进程共享。为防止各进程对系统资源的无序竞争，系统设备必须由系统统一分配。为了实现设备分配，必须在系统中设置相应的数据结构。</p>
<h3 id="5-6-1-设备分配中的数据结构"><a href="#5-6-1-设备分配中的数据结构" class="headerlink" title="5.6.1 设备分配中的数据结构"></a>5.6.1 设备分配中的数据结构</h3><p>在进行设备分配时，通常都需要借助于一些表格的帮助。在表格中记录了相应设备或控制器的状态及对设备或控制器进行控制所需的信息。在进行设备分配时所需的数据结构（表格）有：</p>
<ol>
<li><p>设备控制表（DCT） </p>
<p>系统为每一个设备都配置了一张用于记录本设备情况的设备控制表。</p>
</li>
<li><p>控制器控制表（COCT） </p>
<p>系统为每一个控制器都设置了一张用于记录本控制器情况的控制器控制表。</p>
</li>
<li><p>通道控制表（CHCT） </p>
<p>每个通道都配有一张通道控制表。</p>
</li>
<li><p>系统设备表（SDT） </p>
<p>这是系统范围的数据结构，其中记录了系统中全部设备的情况。每个设备占一个表目，包括有设备类型、设备标识符、设备控制表及设备驱动程序的入口等项。</p>
</li>
</ol>
<h3 id="5-6-2-设备分配算法"><a href="#5-6-2-设备分配算法" class="headerlink" title="5.6.2 设备分配算法"></a>5.6.2 设备分配算法</h3><p>与进程调度的算法相比，对设备进行分配的算法相对简单，通常只采用以下两种分配算法：</p>
<ol>
<li><p>先来先服务 </p>
<p>当有多个进程对同一设备提出 I/O 请求时，该算法根据各进程对某设备提出请求的先后次序，将这些进程排成一个设备请求队列，设备分配程序总是把设备首先分配给队首进程。</p>
</li>
<li><p>优先级高者优先 </p>
<p>在进程调度中，这种算法使得优先权高的进程优先获得处理机。如果对这种高优先权进程所提出的 I/O 请求也赋予高优先权，显然有助于这种进程尽快完成。在利用 该算法形成设备队列时，将优先权高的排在设备队列前面，而对于优先级相同的 I/O 请求，则按先来先服务原则排队。</p>
</li>
</ol>
<h3 id="5-6-3-SPOOLing-技术"><a href="#5-6-3-SPOOLing-技术" class="headerlink" title="5.6.3 SPOOLing 技术"></a>5.6.3 SPOOLing 技术</h3><p>通过 SPOOLing 技术可将一台物理 I/O 设备虚拟为多台逻辑 I/O 设备，同样允许多个用户共享一台物理 I/O 设备。SPOOLing 技术是对脱机输入/输出系统的模拟。</p>
<p>下图显示了脱机输入/输出过程。由于程序和数据的输入和输出都是在外围机的控制下完成的，即它们是在脱离主机的情况下进行的，故称为脱机输入/输出方式。</p>
<p><img src="/images/image-20210810192529491.png" srcset="/img/loading.gif" lazyload alt="image-20210810192529491"></p>
<p>当系统中引入了多道程序技术后，可以利用其中的一道程序，来模拟脱机输入时的外围控制机功能，把低速 I/O 设备上的数据传送到高速磁盘上；再用另一道程序来模拟脱机输出时外围控制机的功能，把数据从磁盘传送到低速输出设备上。这样便可 在主机的直接控制下，实现脱机输入、输出功能。此时的外围操作与 CPU 对数据的处 理同时进行，这种在联机情况下实现的同时外围操作被称为 SPOOLing（Simultaneaus Periphernal Operating On Line），或称为假脱机操作。</p>
<p>SPOOLing 系统主要有以下三部分：</p>
<ol>
<li><p>输入井和输出井。这是在磁盘上开辟的两个大存储空间。输入井是模拟脱机输入时的磁盘设备，用于暂存 I/O 设备输入的数据；输出井是模拟脱机输出时的磁盘，用于暂存用户程序的输出数据。</p>
</li>
<li><p>输入缓冲区和输出缓冲区。输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井。输出缓冲区用于暂存从输出井送来的数据，以后再传送给输出设备。</p>
</li>
<li><p>输入进程和输出进程。输入进程模拟脱机输入时的外围控制机，输出进程模拟脱机输出时的外围控制机。</p>
<p><img src="/images/image-20210810192918093.png" srcset="/img/loading.gif" lazyload alt="image-20210810192918093"></p>
<p>SPOOLing 系统具有如下主要特点：</p>
<ol>
<li>提高了 I/O 的速度</li>
<li>将独占设备改造为共享设备。在 SPOOLing 系统中，实际上并没为任何进程分配设备，而只是在输入井或输出井中为进程分配一个存储区和建立一张 I/O 请求表。这样，便把独占设备改造为共享设备。</li>
<li>实现了虚拟设备功能。</li>
</ol>
</li>
</ol>
<h2 id="5-7-磁盘管理"><a href="#5-7-磁盘管理" class="headerlink" title="5.7 磁盘管理"></a>5.7 磁盘管理</h2><h3 id="5-7-1-磁盘简述"><a href="#5-7-1-磁盘简述" class="headerlink" title="5.7.1 磁盘简述"></a>5.7.1 磁盘简述</h3><ol>
<li><p>数据的组织和格式 </p>
<p>磁盘设备可包括一或多个物理盘片，每个磁盘片分一个或两个存储面，每个磁盘面被组织成若干个同心环，称为磁道，各磁道之间留有必要的间隙，磁道从外向内进行编号。每条磁道又被逻辑上划分成若干个扇区，<strong>一个扇区称为一个盘块（或数据块）</strong>，常常叫做磁盘扇区。各扇区之间保留一定的间隙，一个物理记录存储在一个扇区上。<strong>在微机中，主机对磁盘数据的读写是以扇区为单位的</strong>。磁盘上存储的物理记录块数目由<strong>扇区数</strong>、<strong>磁道数</strong>以及<strong>磁盘面数</strong>所决定。</p>
</li>
<li><p>磁盘的类型 </p>
<p>对磁盘，可以从不同的角度进行分类。最常见的有：将磁盘分成硬盘和软盘、单片盘和多片盘、固定头磁盘和移动头磁盘等。固定头磁盘主要用于大容量磁盘上，而微型机上配置的温盘和软盘都采用移动磁头结构。</p>
</li>
<li><p>磁盘访问时间 </p>
<p>磁盘的访问时间分成以下三部分：首先，把磁头移动到指定磁道上所经历的时间称为<strong>寻道时间</strong>；磁头到达指定磁道后，必须等待指定扇区移动到磁头下面的时间称为<strong>旋转延迟时间</strong>；最后，把数据从磁盘读出或向磁盘写入数据所经历的时间称为<strong>传输时间</strong>。一次磁盘服务的总时间为这三者之和。</p>
</li>
</ol>
<h3 id="5-7-2-磁盘调度"><a href="#5-7-2-磁盘调度" class="headerlink" title="5.7.2 磁盘调度"></a>5.7.2 磁盘调度</h3><p>目前常用的磁盘调度算法有先来先服务、最短寻道时间优先及扫描等算法。</p>
<ol>
<li><p>先来先服务（FCFS，First Come First Served） </p>
<p>先来先服务是一种最简单、也最容易实现的磁盘调度算法。它根据进程请求访问磁盘的先后次序进行调度。此算法的优点是公平、简单，不会出现某一进程的请求长期得不到满足的情况。但此算法平均寻道时间可能较长。</p>
<p>例如，现在有一个请求磁盘服务的队列，要访问的磁道顺序为：98、183、37、122、14、124、65、67，假设磁头最初在 53 道上。</p>
<p>那么，磁头从 53 道移动到 98 道，然后依次移到 183、37、122、14、124、65， 最后到达 67 道，总共移动了 640 个磁道的距离。</p>
</li>
<li><p>最短寻道时间优先（SSTF，Shortest Seek Time First）</p>
<p>该算法要求访问的磁道与当前磁头所在的磁道距离最近，以使每次的寻道时间最短。这种算法不能保证平均寻道时间最短，并且可能导致某个进程发生“饥饿”现象。</p>
<p>例如，用 SSTF 算法处理上面的请求队列。磁头当前在 53 道上，最接近的磁道是 </p>
<p>65。然后下一个移到最接近的 67 道。此时，到 37 道的距离是 30，而到 98 道的距离是 31，故 37 道离 67 道最近，被选为下一个服务对象。接下去的顺序是 l4、98、122、124，最后是 183 道。采用这种方法，磁头共移动了 236 个磁道，是 FCFS 算法的 1/3多一点。很明显，它改善了磁盘服务。</p>
</li>
<li><p>扫描（SCAN）算法</p>
<p>该算法不仅考虑到将要访问的磁道与当前磁道间的距离，更优先考虑的是磁头当前的移动方向。磁头从磁盘的一端出发，向另一端移动，遇到所需的磁道时就进行服务，一旦在当前方向上没有请求了，磁头的移动方向就反过来，继续下面的服务。这种算法避免了出现“饥饿”现象。由于其磁头移动的规律类似电梯的运行，因而常为电梯调度算法。</p>
<p>继续采用前面的例子，用 SCAN 算法处理上面的请求队列，但要知道磁头的移动方向。如果磁头正向 0 道方向移动，那么，它先为 37 道服务，接着是 14 道；到达 14道后，由于在该方向上没有请求了，故磁头移动方向反过来，移向盘的另一端，服务顺序分别是 65，67，98，122，124 和 183 道。</p>
</li>
<li><p>循环扫描（CSCAN）算法 </p>
<p>CSCAN 算法规定磁头单向移动，如只是自里向外移动，当磁头移到最外的磁道并访问后，磁头立即返回到最里的欲访问的磁道，即将最小磁道号紧接着最大磁道号构成循环，进行循环扫描。</p>
<p>用 CSCAN 算法处理上面的请求队列，假设磁头向 0 道方向移动，则顺序为 37、14、183、124、122、98、67、65。</p>
</li>
</ol>
<h3 id="5-7-3-磁盘高速缓存"><a href="#5-7-3-磁盘高速缓存" class="headerlink" title="5.7.3 磁盘高速缓存"></a>5.7.3 磁盘高速缓存</h3><p>磁盘高速缓存是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息。它是一组在逻辑上属于磁盘，而物理上是驻留在内存中的盘块。</p>
<p>当有一进程请求访问某个盘块中的数据时，先去查看磁盘高速缓冲器，若有，直接从中提取数据交付给请求者进程；否则，应先从磁盘中将所要访问的数据读入并交付给请求者进程，同时也将数据送高速缓存。当以后又需要访问该盘块的数据时，便可直接从高速缓存中提取。</p>
<p>将磁盘中的盘块数据读入高速缓存时，会出现因高速缓存中已装满数据而需要将该数据先换出的问题。较常用的置换算法仍然是最近最久未使用算法 LRU、最近未使用算法 NRU 及最少使用算法 LFU 等。</p>
<h3 id="5-7-4-提高磁盘-I-O-速度的其它方法"><a href="#5-7-4-提高磁盘-I-O-速度的其它方法" class="headerlink" title="5.7.4 提高磁盘 I/O 速度的其它方法"></a>5.7.4 提高磁盘 I/O 速度的其它方法</h3><p>除了磁盘高速缓存后，还有几种能有效地提高磁盘 I/O 速度的方法：</p>
<ol>
<li><p>提前读 </p>
<p>进程对文件进行访问时，经常采用顺序访问方式，在读当前块时可以预知下一次要读的盘块。故可以采取预先读方式，即在读当前块的同时，还要求将下一个盘块中的数据也读入缓冲区。</p>
</li>
<li><p>延迟写 </p>
<p>延迟写是指在缓冲区中的数据，本应立即写回磁盘，但考虑到该缓冲区中的数据在不久之后可能还会再被访问，因而并不立即将其数据写入磁盘，而是将它挂在空闲缓冲区队列的末尾。随着空闲缓冲区的使用，缓冲区逐渐移到空闲缓冲队列之首。当再有进程申请到该缓冲区时，才将该缓冲区中的数据写入磁盘，而把该缓冲区作为空闲缓冲区分配出去。</p>
</li>
<li><p>优化物理块的分布 </p>
<p>优化文件物理块的分布是为了使磁头的移动距离最小。该优化应在为文件分配盘块时进行。可将在同一条磁道上的若干个盘块组成<strong>一簇</strong>，在分配存储空间时，以簇为单位进行分配。这样就可以保证在访问这几个盘块时，不必移动磁头或者仅移动一条磁道的距离，从而减少了磁头的平均移动距离。</p>
</li>
<li><p>虚拟盘 </p>
<p>所谓虚拟盘，是指利用内存空间去仿真磁盘，该盘的设备驱动程序也可以接受所有标准的磁盘操作，但这些操作的执行，不是在磁盘上而是在内存中。这些对用户都是透明的。虚拟盘是易失性存储器，一旦系统或电源发生故障，或系统再启动时，原来保存在虚拟盘中的数据将会丢失。因此，虚拟盘通常用于存放临时文件。</p>
<p>虚拟盘与磁盘高速缓存的主要区别在于：虚拟盘中的内容完全由用户控制，而高速磁盘缓存中的内容则是由 OS 控制。</p>
</li>
</ol>
<h3 id="5-7-5-磁盘阵列"><a href="#5-7-5-磁盘阵列" class="headerlink" title="5.7.5 磁盘阵列"></a>5.7.5 磁盘阵列</h3><p>磁盘阵列（RAID，Redundant Array of Independent Disks）是利用一台磁盘阵列控制器，来统一管理和控制一组磁盘驱动器，组成一个高度可靠的、快速的大容量磁盘系统。</p>
<ol>
<li><p>并行交叉存取 </p>
<p>在磁盘存储系统中，有多台磁盘驱动器，系统将每一盘块中的数据分为若干个子盘块数据，再把每一个子盘块的数据分别存储到各个不同磁盘中的相同位置上。当要将一个盘块的数据传送到内存时，采取并行传输方式，将各个盘块中的子盘块数据同时向内存中传输，从而使传输时间大大减少。下图出了磁盘并行交叉存取方式。</p>
<p><img src="/images/image-20210810202206339.png" srcset="/img/loading.gif" lazyload alt="image-20210810202206339"></p>
</li>
<li><p>RAID 的分级 </p>
<p>RAID 原来只有 RAID0 至 RAID5，后来又增加了 RAID6 和 RAID7。</p>
<ol>
<li><p>RAID0 </p>
<p>仅提供了并行交叉存取。RAID 0 没有冗余或错误修复能力，成本低，一般只是在那些对数据安全性要求不高的情况下才被使用。</p>
</li>
<li><p>RAID1 </p>
<p>具有磁盘镜像功能，其比传统的镜盘速度快，但其磁盘容量的利用率只有 50%，它是以牺牲磁盘容量为代价的。</p>
</li>
<li><p>RAID3 </p>
<p>具有并行传输功能的磁盘阵列。它利用一台奇偶校验盘来完成数据的校验功能，比起磁盘镜像，它减少了所需要的冗余磁盘数。如当阵列中只有 7 个盘时，可利用 6 个盘作数据盘，一个盘作校验盘。磁盘的利用率为 6/7。</p>
</li>
<li><p>RAID5 </p>
<p>把校验块分散到所有的数据盘块中，具有独立传送的功能，各磁盘驱动器可独立读/写，常用于 I/O 较频繁的事务处理中。</p>
</li>
<li><p>RAID6 </p>
<p>设置了一个专用的、可快速访问的异步校验盘。该盘具有独立的数据访问通路，具有更好的性能，但改进很有限，且价格昂贵。</p>
</li>
<li><p>RAID7 </p>
<p>即优化的高速数据传送磁盘结构，它所有的 I/O 传送均是同步进行的，可以分别控制，这提高了系统的并行性和系统访问数据的速度，每个磁盘都带有高速缓冲存储器，实时操作系统可以使用任何实时操作芯片，达到不同实时系统的需要。RAID7 是目前最高档次的磁盘阵列。</p>
</li>
</ol>
</li>
</ol>
<h3 id="5-7-6-磁盘容错技术"><a href="#5-7-6-磁盘容错技术" class="headerlink" title="5.7.6 磁盘容错技术"></a>5.7.6 磁盘容错技术</h3><p>磁盘容错技术是通过增加冗余的磁盘驱动器、磁盘控制器等方法，来提高磁盘系统可靠性的一种技术，即当磁盘系统的某部分出现缺陷或故障时，磁盘仍能正常工作，且不致造成数据的丢失或错误。目前广泛采用磁盘容错技术来改善磁盘系统的可靠性。磁盘容错技术往往也被人们称为系统容错技术 SFT，它分成三个级别：第一级是低级磁盘容错技术；第二级是中级磁盘容错技术；第三级是系统容错技术，它基于集群技术实现容错。</p>
<ol>
<li><p>第一级容错技术 SFT-I </p>
<p>第一级容错技术是最基本的一种磁盘容错技术，主要用于防止因磁盘表面缺陷所造成的数据丢失。它包含双份目录、双份文件分配表及写后读校验等措施。</p>
<p>1）双份目录和双份文件分配表 </p>
<p>在磁盘上存放的文件目录和文件分配表 FAT，是文件管理所用的重要数据结构。 为了防止这些表格被破坏，可在不同的磁盘上或在磁盘的不同区域中，分别建立双份目录表和 FAT。</p>
<p>2）写后读校验 </p>
<p>为了保证所有写入磁盘的数据都能写入到完好的盘块中，应该在每次从内存缓冲区向磁盘中写入一个数据块后，又立即从磁盘上读出该数据块，并送至另一缓冲区中，再将该缓冲区内容与内存缓冲区中在写后仍保留的数据进行比较。若两者一致，便认为此次写入成功，可继续写下一个盘块；否则，再重写。</p>
</li>
<li><p>第二级容错技术 SFT-II </p>
<p>第二级容错技术主要用于防止由磁盘驱动器和磁盘控制器故障所导致的系统不能正常工作，它具体又可分为磁盘镜像和磁盘双工。</p>
<ul>
<li>磁盘镜像功能，是在同一磁盘控制器下再增设一个完全相同的磁盘驱动器，在每次向主磁盘写入数据后，都需要将数据再写到备份磁盘上，使两个磁盘上具有完全相同的位像图。</li>
<li>磁盘双工功能，即将两台磁盘驱动器分别接到两个磁盘控制器上，同样使这两台磁盘机镜像成对。在磁盘双工时，文件服务器同时将数据写到两个处于不同控制器下的磁盘上，使两者有完全相同的位像图。如果某个通道或控制器发生故障时，另一通道上的磁盘仍能正常工作，不会造成数据的丢失。</li>
</ul>
</li>
<li><p>基于集群技术的容错功能 SFT-III </p>
<p>所谓集群，是指由一组互连的自主计算机组成统一的计算机系统。利用集群系统不仅可提高系统的并行处理能力，还可用于提高系统的可用性，它们是当前使用最广泛的一类具有容错功能的集群系统。其主要工作模式有三种：热备份模式；互为备份模式；公用磁盘模式。</p>
<p>1）双机热备份模式</p>
<p>系统中备有两台服务器，两者的处理能力通常是完全相同的，一台作为主服务器， 另一台作为备份服务器。平时主服务器运行，备份服务器则时刻监视着主服务器的运行，一旦主服务器出现故障，备份服务器便立即接替主服务器的工作而成为系统中的主服务器，修复后的服务器再作为备份服务器。</p>
<p>2）双机互为备份的模式 </p>
<p>这种模式中，两台服务器均为在线服务器，它们各自完成自己的任务；同时它们还接收另一台服务器发来的备份数据，作为对方的备份服务器。如果其中一台服务器 发生了故障，则由另一台服务器为客户机提供服务；当故障服务器修复并重新连到网上后，已被迁移到无故障服务器上的服务功能将被返回，恢复正常工作。</p>
<p>3）公用磁盘模式 </p>
<p>为了减少信息复制的开销，可以将多台计算机连接到一台公共的磁盘系统上去。该公共磁盘被划分为若干个卷，每台计算机使用一个卷。如果某台计算机发生故障， 此时系统将重新进行配置，根据某种调度策略来选择另一台替代机器，后者对发生故障的机器的卷拥有所有权，从而来接替故障计算机所承担的任务。公用磁盘模式的优点是：消除了信息的复制时间，因而减少了网络和服务器的开销。</p>
</li>
</ol>
<h1 id="6-文件管理"><a href="#6-文件管理" class="headerlink" title="6. 文件管理"></a>6. 文件管理</h1><h2 id="6-1-基本概念"><a href="#6-1-基本概念" class="headerlink" title="6.1 基本概念"></a>6.1 基本概念</h2><p>计算机系统中有大量的程序，所有程序在运行过程中都需要保存和读取信息。为了实现大量信息的长期方便共享，通常系统中的绝大部分信息都存放在外存，对这些信息的存放和管理必须利用文件和文件系统。</p>
<p>文件是指具有文件名的若干相关元素的集合。元素通常是记录，而记录又是一组有意义的数据项的集合。</p>
<p>文件系统是操作系统中负责操纵和管理文件的一整套机制，它实现文件的共享和保护，方便用户“按名存取”。有了文件系统，用户可以用文件名对文件实施存取和相应管理，而不必去考虑其信息的存放、如何去启动设备进行 I/O 等实现的细节。文件系统提供了用户与外存的界面，一般由文件管理有关的软件、被管理的文件及实施文件管理所需的数据结构组成。</p>
<h3 id="6-1-1-文件、记录和数据项"><a href="#6-1-1-文件、记录和数据项" class="headerlink" title="6.1.1 文件、记录和数据项"></a>6.1.1 文件、记录和数据项</h3><p>文件系统中把数据分为<strong>数据项</strong>、<strong>记录</strong>和<strong>文件</strong>三级。</p>
<ol>
<li><p>数据项 </p>
<p>数据项是数据记录中最基本的、不可分的数据单位。数据项可以是字母、数字或两者的组合。通过数据类型（逻辑、数值、字符等）及数据长度来描述。在文件系统中，数据项是最低级的数据组织形式，用来描述实体的某种属性，例如，学号/201709001、姓名/张三、性别/男等。</p>
</li>
<li><p>记录 </p>
<p>记录是一组相关数据项的集合，用于描述一个对象在某方面的属性。为了能唯一地标识一个记录，必须在一个记录的各个数据项中，确定出一个或几个数据项，把它们的集合称为关键字。关键字是唯一能标识一个记录的数据项。</p>
</li>
<li><p>文件 </p>
<p>文件是具有文件名的、在逻辑上具有完整意义的一组相关信息项的有序序列。文件信息由文件创建者和使用者定义，文件信息的类型可以是源程序、目标程序、可执行文件、图像和声音等。系统通过文件名可以访问文件，名字的长度因系统不同而异。 文件可分为有结构文件和无结构文件两种。在有结构的文件中，文件由若干个相关记录组成；而无结构文件则被看成是一个字符流。</p>
<p>文件都有文件名和数据，操作系统为了方便管理还会保存与文件相关的信息，这些附加信息就是文件属性。文件的属性可以包括：文件类型、文件长度、文件的物理位置、文件的建立时间、最后一次修改时间等。</p>
</li>
</ol>
<h3 id="6-1-2-文件类型"><a href="#6-1-2-文件类型" class="headerlink" title="6.1.2 文件类型"></a>6.1.2 文件类型</h3><p>为了便于管理和控制文件，通常将文件分成若干种类型。在许多操作系统中都把文件类型作为扩展名而放在文件名的后面，在文件名和扩展名之间用“．”号隔开。下面是常用的几种文件分类方法。</p>
<ol>
<li><p>按用途分类 </p>
<p>根据文件的性质和用途的不同，可将文件分为三类：</p>
<p>1）系统文件 </p>
<p>通常是操作系统核心、各种系统应用程序及数据组成。只允许用户通过系统调用来执行该类文件，不允许对这类文件进行读写和修改操作。</p>
<p>2）用户文件 </p>
<p>指由用户的源代码、目标文件、可执行文件或数据等所构成的文件。</p>
<p>3）库文件 </p>
<p>是由标准子例程及常用的例程等所构成的文件。这类文件允许用户调用，但不允许修改。</p>
</li>
<li><p>按文件中数据的形式分类</p>
<p>按文件中数据的形式分类，也可把文件分为三类：</p>
<p>1）源文件 </p>
<p>通常是指由高级语言或汇编语言所编写的程序，由源程序和数据构成的文件。</p>
<p>2）目标文件 </p>
<p>是指把源程序经过相应语言的编译程序编译过，但尚未经过链接程序链接的目标代码所构成的文件。它属于二进制文件，通常后缀名是“.obj”。</p>
<p>3）可执行文件 </p>
<p>是指把编译后所产生的目标代码再经过链接程序链接后所形成的文件。</p>
</li>
<li><p>按存取控制属性分类 </p>
<p>根据系统管理员或用户所规定的存取控制属性，可将文件分为三类：</p>
<p>1）只执行文件 </p>
<p>只允许被核准的用户调用执行，既不允许读，更不允许写。</p>
<p>2）只读文件 </p>
<p>只允许文件主及被核准的用户去读，但不允许写。</p>
<p>3）读写文件 </p>
<p>是指允许文件主和被核准的用户去读或写的文件。</p>
</li>
<li><p>按组织形式和处理方式分类 </p>
<p>根据文件的组织形式和系统对其的处理方式，可将文件分为三类：</p>
<p>1）普通文件 </p>
<p>由 ASCII 码或二进制码组成的字符文件。一般用户建立的源程序文件、数据文件、目标代码文件及操作系统自身代码文件、库文件、实用程序文件等都是普通文件，通常存储在外存上。</p>
<p>2）目录文件 </p>
<p>由文件目录组成的，用来管理和实现文件系统功能的系统文件，通过目录文件可以对其它文件的信息进行检索。</p>
<p>3）特殊文件 </p>
<p>特指系统中的各类 I/O 设备。为了便于统一管理，系统将所有的输入/输出设备都视为文件，按文件方式提供给用户使用。根据设备数据交换单位的不同，又可将特殊文件分为块设备文件和字符设备文件。前者用于磁盘、光盘或磁带等块设备的 I/O 操作，而后者用于终端、打印机等字符设备的 I/O 操作。</p>
</li>
</ol>
<h3 id="6-1-3-文件操作"><a href="#6-1-3-文件操作" class="headerlink" title="6.1.3 文件操作"></a>6.1.3 文件操作</h3><p>用户通过文件系统所提供的系统调用实施对文件的操作。最基本的文件操作有：创建文件、删除文件、读文件、写文件、截断文件和设置文件的读/写位置。但对于一 个实际的 OS，提供了更多的对文件的操作，如打开和关闭一个文件、改变文件名等操作。</p>
<p>有许多文件操作都可以利用上述基本操作加以组合来实现。如创建一个文件拷贝的操作，可利用两条基本操作来实现：第一步利用创建文件的系统调用来创建一个新文件；第二步将原有文件中的内容写入新文件中。</p>
<h3 id="6-1-4-文件结构"><a href="#6-1-4-文件结构" class="headerlink" title="6.1.4 文件结构"></a>6.1.4 文件结构</h3><p>对于任何一个文件，都存在着两种形式的结构：逻辑结构和物理结构。</p>
<ol>
<li><p>文件的逻辑结构 </p>
<p>文件的逻辑结构是从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构，它独立于文件的物理特性。</p>
</li>
<li><p>文件的物理结构 </p>
<p>文件的物理结构又称为文件的存储结构，是指文件在外存上的存储组织形式。它不仅与存储介质的存储性能有关，而且与所采用的外存分配方式有关。</p>
</li>
</ol>
<h2 id="6-2-文件的逻辑结构"><a href="#6-2-文件的逻辑结构" class="headerlink" title="6.2 文件的逻辑结构"></a>6.2 文件的逻辑结构</h2><p>文件的逻辑结构可分为两大类，一类是有结构文件，指由一个以上的记录构成的文件，又称为记录式文件；其二是无结构文件，指由字符流构成的文件，又称为流式文件。</p>
<ol>
<li><p>有结构文件 </p>
<p>在有结构文件中，依据记录的长度可分为定长和不定长两类：</p>
<p>1）定长记录 </p>
<p>是指文件中所有记录具有相同的长度，同时所有数据项都处在记录中相同的位置，具有相同的顺序和长度。定长记录由于处理方便、控制容易，在传统的数据处理中普遍采用。</p>
<p>2）变长记录 </p>
<p>是指文件中各记录的长度不相同。但在处理前，每个记录的长度是可知的。</p>
<p>根据用户和系统管理上的需要，可采用多种方式来组织这些记录，形成以下几种文件：</p>
<ol>
<li><p>顺序文件 </p>
<p>顺序文件把一组记录作为一个列表来存储和管理，记录中包含一定信息的基本单位，这些信息可有若干个字段，字段个数相同，每个字段的长度也相同。</p>
</li>
<li><p>索引文件 </p>
<p>为文件中所有记录建立一张索引表，索引表记录文件中的每个记录所在的位置。查找时检索索引表找到相应的表项，就能访问所需文件中的变长记录。通常将存放记录的文件称为主文件，而存放索引信息的文件称为索引文件。</p>
</li>
<li><p>索引顺序文件 </p>
<p>它将顺序文件中的所有记录分为若干个组，并建立一张索引表，在索引表中为每组中的第一个记录建立一个索引项，其中含有该记录的键值和指向该记录的指针。</p>
</li>
</ol>
</li>
<li><p>无结构文件 </p>
<p>无结构文件是指对文件内的信息不再划分单位，而是依次的一串字符流构成的文件，也被称为流式文件。在流式文件中，查找文件的基本信息单位比较困难，但管理简单，用户可以方便地对其进行操作。因此，那些对基本信息单位操作不多的文件较适于采用无结构方式存储，如源程序文件、目标代码文件等。在 Unix 系统中，所有的文件都被看作是流式文件。</p>
</li>
</ol>
<h2 id="6-3-文件的物理结构"><a href="#6-3-文件的物理结构" class="headerlink" title="6.3 文件的物理结构"></a>6.3 文件的物理结构</h2><h3 id="6-3-1-外存分配方式"><a href="#6-3-1-外存分配方式" class="headerlink" title="6.3.1 外存分配方式"></a>6.3.1 外存分配方式</h3><p>外存分配方式决定了文件的物理结构。采用不同的分配方式时，将形成不同的文件物理结构，如采用连续分配方式时的文件物理结构，将是顺序式的文件结构；链接分配方式将形成链接式文件结构；而索引分配方式则将形成索引式的文件结构。</p>
<p>目前常用的外存分配方法有<strong>连续分配</strong>、<strong>链接分配</strong>和<strong>索引分配</strong>三种。</p>
<ol>
<li><p>连续分配 </p>
<p>连续分配要求为每一个文件分配一组相邻接的盘块。这种分配方式保证逻辑文件中的记录顺序与存储器中文件占用盘块的一致性。连续分配的优点是：顺序访问容易，速度快。其缺点是要求有连续的存储空间，且必须事先知道文件的长度。</p>
</li>
<li><p>链接分配 </p>
<p>采用链接分配方式时，可通过在每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表，把这样形成的物理文件称为链接文件。链接分配无需事先知道文件的大小，对文件的增、删、改也十分方便，并且由于采取离散分配方式，消除了外部碎片，故显著地提高了外存空间的利用率。</p>
<p>链接方式可分为隐式链接和显式链接两种形式。</p>
<p>1）隐式链接 </p>
<p>在采用隐式链接分配方式时，在文件目录的每个目录项中，都须含有指向链接文件第一个盘块和最后一个盘块的指针，而在每个盘块中都含有一个指向下一个盘块的指针。</p>
<p>隐式链接分配方式只适合于顺序访问，随机访问的效率低下。此外，只通过链接指针链接盘块，可靠性较差，只要其中任何一个指针出现问题，都会导致整个链断开。</p>
<p>2）显式链接 </p>
<p>显式链接是指把用于链接文件各物理块的指针，显式地存放在内存的一张链接表中。该表在整个磁盘仅设置一张，表的序号是物理盘块号，在每个表项中存放链接指针，即下一个盘块号。由于分配给文件的所有盘块号都放在该表中，故把该表称为文件分配表 FAT（File Allocation Table）。</p>
<p>为了适应磁盘容量不断增大的需要，在进行盘块分配时，不再以盘块而是以簇(cluster)为基本单位。簇是一组连续的扇区，在 FAT 中它作为一个虚拟扇区，一个簇应包含扇区的数量与磁盘容量的大小直接有关。</p>
</li>
<li><p>索引分配</p>
<p>1）单级索引分配 </p>
<p>链接分配方式不能支持高效的直接存取，且 FAT 需占用较大的内存空间。索引分配方法为每个文件分配一个索引块，再把分配给该文件的所有盘块号都记录在该索引块中，因而该索引块就是一个含有许多盘块号的数组。在建立一个文件时，只需在为之建立的目录项中填上指向该索引块的指针。</p>
<p>索引分配方式支持直接访问。通常采用一个专门的盘块作为索引块，其中可存放成百个、甚至上千个盘块号。可见，对于小文件采用索引分配方式时，其索引块的利用率极低。</p>
<p>2）多级索引分配 </p>
<p>当 OS 为一个大文件分配磁盘空间时，如果所分配出去的盘块的盘块号已经装满一个索引块时，OS 便为该文件分配另一个索引块，用于将以后继续为之分配的盘块号记录于其中，依此类推。此时，应为这些索引块再建立一级索引，称为第一级索引， 即系统再分配一个索引块，作为第一级索引的索引块，将第一块、第二块……等索引块的盘块号填入到此索引表中，这样便形成了两级索引分配方式。如果文件非常大时，还可用三级、四级索引分配方式。</p>
<p>两级索引分配方式下，若每个盘块的大小为 1 KB，每个盘块号占 4 个字节，则在一个索引块中可存放 256 个盘块号。则两级索引时，最多可包含存放文件的盘块的盘块号总数<em>N</em> = 256×256 = 64 K个。故采用两级索引时，所允许的文件最大长度为64 MB。</p>
<p>3）混合索引分配方式 </p>
<p>所谓混合索引分配方式，是指将多种索引分配方式相结合而形成的一种分配方式。如系统既采用了直接地址，又采用了一级索引分配方式，或两级索引分配方式，甚至还采用了三级索引分配方式。这种混合索引分配方式已在 Unix 系统中采用。</p>
</li>
</ol>
<h3 id="6-3-2-文件的物理结构"><a href="#6-3-2-文件的物理结构" class="headerlink" title="6.3.2 文件的物理结构"></a>6.3.2 文件的物理结构</h3><p>文件物理结构是指文件在存储介质上的组织方式，它依赖于物理的存储设备、物理存储空间，可以看做是相关物理块的集合，又称物理文件。</p>
<ol>
<li><p>顺序结构 </p>
<p>顺序结构是把一个逻辑上顺序的记录构成的文件分配到顺序的物理块中。</p>
<ul>
<li>优点：管理简单，存储速度快。</li>
<li>缺点：空间利用率低，文件记录插入或删除操作不方便，只能在文件末尾进行。</li>
</ul>
</li>
<li><p>链接结构 </p>
<p>链接结构是把文件信息存放在非连续的物理块中，每个物理块均设有一个指针指向其后续的另一个物理块，从而使得存放同一文件的物理块链接成一个串联队列。链接方式又分显式链接和隐式链接。显式链接的指针在专门的链接表中，隐式链接的指针在存放文件信息的物理块中。</p>
<ul>
<li>优点：链接结构空间利用率高，且易于文件扩充</li>
<li>缺点：对文件的搜索率较低</li>
</ul>
</li>
<li><p>索引结构 </p>
<p>索引结构是为每个文件建立一个索引表，其中每一个表项指出文件记录所在的物理块号，表项按逻辑记录编号，按顺序或按记录内某一关键字顺序排列。对于大文件，为检索方便，可以建立多级索引，还可以把文件索引表也作为一个文件，称为索引表文件。</p>
<ul>
<li>优点：满足文件动态增长的要求且存取方便</li>
<li>缺点：建立索引表增加了文件存储空间的开销，对于多级索引，访问时间开销较大</li>
</ul>
</li>
</ol>
<h2 id="6-4-文件存储空间管理"><a href="#6-4-文件存储空间管理" class="headerlink" title="6.4 文件存储空间管理"></a>6.4 文件存储空间管理</h2><p>文件管理要解决的重要问题之一是如何为新创建的文件分配存储空间。存储空间的基本分配单位都是磁盘块而非字节。下面介绍几种常用的文件存储空间的管理方法。</p>
<ol>
<li><p>空闲表法 </p>
<p>空闲表法属于连续分配方式，它与内存的动态分配方式相似，它为每个文件分配一块连续的存储空间，即系统也为外存上的所有空闲区建立一张空闲表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息，再将所有空闲区按其起始盘块号递增的次序排列。</p>
</li>
<li><p>空闲链表法 </p>
<p>空闲链表法是将所有空闲盘区拉成一条空闲链。根据构成链所用基本元素的不同，可把链表分成两种形式：空闲盘块链和空闲盘区链。空闲盘块链将磁盘上的所有空闲空间，以盘块为单位拉成一条链。而空闲盘区链将磁盘上的所有空闲盘区（每个盘区可包含若干个盘块）拉成一条链。</p>
</li>
<li><p>位示图</p>
<p>位示图的基本思想是：用若干个字节组成一张图，每个字节中的每一位对应存储空间中的一个物理块。当其值为“0”时，表示对应的盘块空闲；为“1”时，则表示已分配。有的系统标志方式则正好相反。这样，由所有盘块所对应的位构成一个集合，称为位示图。位示图的大小由盘块总数确定，通常可用 m×n 个位数来构成位示图，m×n 大于等于磁盘的总块数</p>
<p><img src="/images/image-20210810213007341.png" srcset="/img/loading.gif" lazyload alt="image-20210810213007341"></p>
<p>若某盘块对应的位处于位示图的第 i 行第 j 列，则其相应的盘块号 b 为：b = n (i -1) + j</p>
<p>其中，n 代表每行的位数。</p>
</li>
<li><p>成组链接法 </p>
<p>空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太长。在 Unix 系统中采用的是成组链接法，这是将上述两种方法相结合而形成的一种空闲盘块管理方法。</p>
<p><img src="/images/image-20210810213250360.png" srcset="/img/loading.gif" lazyload alt="image-20210810213250360"></p>
<p>文件区中的所有空闲盘块被分成若干个组，将每一组含有的盘块总数 N 和该组所有的盘块号记入其前一组的第一个盘块中。这样，由各组的第一个盘块可链成一条链。将第一组的盘块总数和所有的盘块号记入空闲盘块号栈中，作为当前可供分配的空闲盘块号。</p>
<p>使用成组链接法进行了上述分组之后，系统可根据申请的要求进行空闲盘块的分配，并在释放文件时回收空闲盘块。</p>
</li>
</ol>
<h2 id="6-5-目录管理"><a href="#6-5-目录管理" class="headerlink" title="6.5 目录管理"></a>6.5 目录管理</h2><p>文件目录是一组逻辑上的文件和子目录的集合，是一种管理文件系统中所有文件的机制。在目录管理中要求能实现文件的“按名存取”，即系统根据用户所提供的文件名，能快速准确地找到指定文件在外存上的存储位置。</p>
<h3 id="6-5-1-文件控制块和索引结点"><a href="#6-5-1-文件控制块和索引结点" class="headerlink" title="6.5.1 文件控制块和索引结点"></a>6.5.1 文件控制块和索引结点</h3><p>为了能对一个文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构，称之为“文件控制块（FCB）”。文件管理程序可借助于文件控制块中的信息，对文件施以各种操作。</p>
<ol>
<li><p>文件控制块</p>
<p>文件控制块通常含有三类信息，即基本信息、存取控制信息及使用信息。基本信息类包括文件名、文件物理位置、文件逻辑结构、文件的物理结构；存取控制信息类 包括文件主的存取权限、核准用户的存取权限以及一般用户的存取权限；使用信息类包括文件的建立日期和时间、文件上一次修改的日期和时间、当前使用信息等。</p>
</li>
<li><p>索引结点</p>
<p>随着文件的说明信息不断的增加，会使得目录项变得很大，从而占用大量的空间。由于目录通常存放在磁盘中，因此文件目录可能占用大量的盘块。在检索目录文件的过程中，只用到了文件名，而其它一些对该文件进行描述的信息，检索时一概不用。</p>
<p>为了加快对文件目录的查找，Unix 系统采用了把文件名和文件的说明信息分开的办法，由文件说明信息形成一个称为索引结点的数据结构，简称为 i 结点。文件目录只是将文件名和它的索引结点号结合在一起的一张表，目录中的每个目录项仅由文件 名和对应的 i 结点的指针所构成。这样，每个盘块能存放的目录项数量增加，从而查找一个文件平均需启动磁盘的次数减少，节省了系统开销。</p>
</li>
</ol>
<h3 id="6-5-2-目录结构"><a href="#6-5-2-目录结构" class="headerlink" title="6.5.2 目录结构"></a>6.5.2 目录结构</h3><p>文件目录是文件系统的关键数据结构，文件系统的基本功能之一就是负责文件目录的建立、维护和检索，要求文件实现按名存取。目前常用的目录结构形式有<strong>单级目录</strong>、<strong>两级目录</strong>和<strong>多级目录</strong>。</p>
<ol>
<li><p>单级目录结构 </p>
<p>这是最简单的目录结构。在整个文件系统中只建立一张目录表，每个文件占一个目录项，目录项中含文件名、文件扩展名、文件长度、文件类型、文件物理地址以及其它文件属性。</p>
<p>单级目录的优点是简单且能实现目录管理的基本功能——按名存取，但却存在一些缺点：查找速度慢；不允许重名；不便于实现文件共享；单级目录要求所有用户都用同一个名字来访问同一文件，因此单级目录只能适用于单用户环境。</p>
</li>
<li><p>两级目录</p>
<p>为了克服单级目录所存在的缺点，可以为每一个用户建立一个单独的用户文件目录 UFD（User File Directory）。这些文件目录具有相似的结构，它由用户所有文件的 文件控制块组成。此外，在系统中再建立一个主文件目录 MFD（Master File Directory）；在主文件目录中，每个用户目录文件都占有一个目录项，其目录项中包括用户名和指向该用户目录文件的指针。</p>
<p>两级目录结构基本上克服了单级目录的缺点，并具有以下优点：提高了检索目录的速度；在不同的用户目录中，可以使用相同的文件名；不同用户还可使用不同的文件名来访问系统中的同一个共享文件。</p>
</li>
<li><p>多级目录结构</p>
<ol>
<li>目录结构 </li>
</ol>
<p>对于大型文件系统，通常采用三级或三级以上的目录结构，以提高对目录的检索速度和文件系统的性能。多级目录结构又称为树型目录结构，主目录在这里被称为根目录，把数据文件称为树叶，其它的目录均作为树的结点。</p>
<ol start="2">
<li>路径名 </li>
</ol>
<p>在树形目录结构中，从根目录到任何数据文件，都只有一条唯一的通路。在该路径上从树的根（即主目录）开始，把全部目录文件名与数据文件名依次地用“/”连接起来，即构成该数据文件的路径名。系统中的每一个文件都有唯一的路径名。</p>
<ol start="3">
<li>当前目录 </li>
</ol>
<p>当前目录是指当前访问所处目录结构中的位置，有时也称为当前工作目录。当前目录常和相对路径名一起使用。用户指定一个目录为当前目录，这时所有不从根目录开始的路径名都是相对于当前的工作目录的。从当前目录开始直到数据文件为止所构成的路径名，称为<strong>相对路径</strong>名；而从根目录开始的路径名称为<strong>绝对路径</strong>名。</p>
<p>目前，大多数操作系统如 Unix、Linux 和 Windows 系列都采用了多级目录结构。</p>
</li>
</ol>
<h3 id="6-5-3-目录查询技术"><a href="#6-5-3-目录查询技术" class="headerlink" title="6.5.3 目录查询技术"></a>6.5.3 目录查询技术</h3><p>目前对目录进行查询的方式有两种: 线性检索法和 Hash 方法。</p>
<ol>
<li><p>线性检索法 </p>
<p>线性检索法又称为顺序检索法。在单级目录中，利用用户提供的文件名，用顺序查找法直接从文件目录中找到指名文件的目录项。在树型目录中，用户提供的文件名是由多个文件分量名组成的路径名，此时须对多级目录进行查找。</p>
</li>
<li><p>Hash 方法 </p>
<p>如果建立了一张 Hash 索引文件目录，便可利用 Hash 方法进行查询，即系统利用用户提供的文件名并将它变换为文件目录的索引值，再利用该索引值到目录中去查找，这将显著地提高检索速度。</p>
</li>
</ol>
<h2 id="6-6-文件共享和保护"><a href="#6-6-文件共享和保护" class="headerlink" title="6.6 文件共享和保护"></a>6.6 文件共享和保护</h2><h3 id="6-6-1-文件共享"><a href="#6-6-1-文件共享" class="headerlink" title="6.6.1 文件共享"></a>6.6.1 文件共享</h3><p>文件共享是指系统允许多个用户使用同一个文件，其主要目的，一是提高文件存储空间的利用率，二是方便用户对文件的使用。目前常用的文件共享方式有基于索引结点的共享方式和利用符号链实现文件共享两种：</p>
<ol>
<li><p>基于索引结点的共享方式 </p>
<p>是指将多个目录项指向同一个磁盘索引结点的共享方式。该方式的缺点是文件主无法删除被他人共享的文件。</p>
<p>在索引结点中有一个链接计数 count，用于表示链接到本索引结点（即文件）上的用户目录项的数目。当 count=2 时，表示有两个用户目录项链接到本文件上，或者说是有两个用户共享此文件。</p>
<p>如当用户 A 创建一个新文件时，他便是该文件的所有者，此时将 count 置 1。当有用户 B 要共享此文件时，在用户 B 的目录中增加一目录项，并设置一个指针指向该文件的索引结点，此时，文件主仍然是 A，count=2。如果用户 A 不再需要此文件，并不能将此文件删除，若删除了该文件，也必然删除了该文件的索引结点，这样会使 B的指针悬空，而 B 可能正在此文件上执行写操作，此时将半途而废。</p>
</li>
<li><p>利用符号链实现文件共享 </p>
<p>这是指通过建立一个类型为 LINK、内容为被共享文件路径名的新文件来实现共享的方式。其一大优点是，只要简单提供一个机器的网络地址，以及文件在该机器中的文件路径名，就可链接全球任一处机器上的文件。</p>
<p>在利用符号链方式实现文件共享时，只有文件主才拥有指向其索引结点的指针，共享该文件的其他用户则只有该文件的路径名，并不拥有指向其索引结点的指针。这样，也就不会发生在文件主删除共享文件后留下一悬空指针的情况。当文件的拥有者把一个共享文件删除后，其他用户试图通过符号链去访问一个已被删除的共享文件时， 会因系统找不到该文件而使访问失败，于是再将符号链删除，此时不会产生任何影响。</p>
</li>
</ol>
<h3 id="6-6-2-文件保护"><a href="#6-6-2-文件保护" class="headerlink" title="6.6.2 文件保护"></a>6.6.2 文件保护</h3><p>文件保护用来防止文件受到物理破坏和非法访问。</p>
<ol>
<li><p>访问类型 </p>
<p>对文件的保护可以从限制对文件的访问类型出发，可以加以控制的访问类型有：读、写、执行、添加、删除等。此外，还可以对文件的重命名、复制、编辑等加以控制。</p>
</li>
<li><p>访问控制 </p>
<p>访问控制就是对不同的用户访问同一个文件采取不同的访问类型。根据用户的权限不同，可以把用户划分为拥有者、工作组用户、其他用户等。然后对不同的用户组采取不同的访问类型，从而保护文件，防止文件被非法访问。</p>
</li>
<li><p>保护措施 </p>
<p>文件被破坏，有时是硬件故障、软件错误引起的，有时是用户共享文件时使用未授权的操作引起的，也可能是由于非法用户的使用造成的，因此，文件系统应根据不同情况，采用不同的保护措施。</p>
<ol>
<li>防止系统故障造成的破坏</li>
</ol>
<p>文件系统必须有防止硬、软件的各种意外可能破坏文件的能力，为此，文件系统经常采用建立副本和文件转储的方法来保护文件。</p>
<ul>
<li><p>建立副本：是指把同一文件保存到多个存储介质上作为备用副本，以便恢复被丢失的文件信息，增强系统存储文件的可靠性。</p>
</li>
<li><p>文件转储：是指每隔一定的时间把文件转储到其它的存储介质上，有全部存储和增量存储两种方式。其中全部存储是指把某一文件存储器的全部信息都定期复制到磁带。增量转储是指定期转储那些上次转储以来被修改过的文件和目录。</p>
<p>文件转储不仅可以保护用户文件，而且当系统出现故障时，可用该办法修复系统。</p>
</li>
</ul>
<ol start="2">
<li>防止用户共享文件可能造成的破坏 </li>
</ol>
<p>对共享文件要防止用户非法使用造成的破坏，这就涉及到用户对文件的使用权限，通常可以用下列方法来规定使用权限：</p>
<ol>
<li>存取控制矩阵：用一个二维矩阵列出每个用户对每个文件或子目录的存取权限。</li>
<li>存取控制表：为每个文件建立一张存取控制表，表中指出各类用户对该文件的存储权限。</li>
<li>用户权限表：对于系统中每一个用户给出一张用户权限表，列出授权可访问的文件清单及所具有的访问权限。</li>
</ol>
<ol start="3">
<li>防止非法用户窃取、破坏文件</li>
</ol>
<p>为防止未经文件拥有者授权的用户窃取或破坏文件，可采用如下三种保密措施：</p>
<ol>
<li>隐蔽文件目录：通过专用命令将保密文件的文件目录隐蔽起来，不在显示器上显示，使非授权用户不知道文件名，无法使用文件。</li>
<li>设置口令：设置口令的方法有两种，一种是建立文件时，把口令存放在文件目录中；另一种是为每个注册用户规定一个口令，当用户欲使用文件时，须提供口令，只有与所设置的口令相符才能访问文件。</li>
<li>使用密码：使用密码是指用户在保存文件时进行加密，生成密码文件，使用文件时再将其解密，只有持有密钥的用户才能正确读出被加密的文件，非授权用户无法窃取文件信息。</li>
</ol>
</li>
</ol>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/">计算机基础知识</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/08/11/9.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">计算机网络与安全</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2021/08/09/6%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/">
                        <span class="hidden-mobile">计算机组成原理</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.3/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.1/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.8/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.12/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>















<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
